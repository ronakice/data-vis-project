{
    "x": {
        "0": 12.14089298248291,
        "1": 3.571119785308838,
        "2": 0.5986799597740173,
        "3": 5.6159586906433105,
        "4": 12.075216293334961,
        "5": 9.577703475952148,
        "6": 0.5491706132888794,
        "7": 9.565518379211426,
        "8": 3.381775379180908,
        "9": -12.435070991516113,
        "10": 5.617804050445557,
        "11": 8.938515663146973,
        "12": 6.850238800048828,
        "13": -0.8651973009109497,
        "14": 13.509756088256836,
        "15": 3.6718573570251465,
        "16": -11.043335914611816,
        "17": 1.3852359056472778,
        "18": 1.9852783679962158,
        "19": 7.089998722076416,
        "20": -6.103789329528809,
        "21": 7.938986301422119,
        "22": 2.1058554649353027,
        "23": 0.9977085590362549,
        "24": -12.434208869934082,
        "25": 4.771424293518066,
        "26": -9.913907051086426,
        "27": 5.303035736083984,
        "28": -2.2646701335906982,
        "29": -6.566475868225098,
        "30": 2.090512990951538,
        "31": 3.342261552810669,
        "32": -4.052497386932373,
        "33": 8.569063186645508,
        "34": 7.635442733764648,
        "35": 7.577878475189209,
        "36": -3.9944183826446533,
        "37": 11.723783493041992,
        "38": -0.15705470740795135,
        "39": 1.9836180210113525,
        "40": 4.764511585235596,
        "41": -16.83216094970703,
        "42": 6.409578323364258,
        "43": 1.6476207971572876,
        "44": 5.411258697509766,
        "45": 8.837949752807617,
        "46": -4.010929107666016,
        "47": -5.288848400115967,
        "48": -15.901225090026855,
        "49": 8.704957008361816,
        "50": 4.149826526641846,
        "51": 3.409069538116455,
        "52": -10.071349143981934,
        "53": 11.073812484741211,
        "54": -6.78408670425415,
        "55": -6.098377704620361,
        "56": 6.505460262298584,
        "57": 0.39087024331092834,
        "58": -5.113418102264404,
        "59": -16.523868560791016,
        "60": 7.021394729614258,
        "61": -3.69273042678833,
        "62": 11.622329711914062,
        "63": -2.1584136486053467,
        "64": -1.3529536724090576,
        "65": 4.578511714935303,
        "66": 2.4462504386901855,
        "67": -4.219226837158203,
        "68": 4.46319580078125,
        "69": -2.4163646697998047,
        "70": 1.4211270809173584,
        "71": 6.191157817840576,
        "72": 8.982061386108398,
        "73": 3.1742513179779053,
        "74": -10.083858489990234,
        "75": 1.6698116064071655,
        "76": 4.747348785400391,
        "77": 8.760891914367676,
        "78": -15.269477844238281,
        "79": -2.1238083839416504,
        "80": -6.578175067901611,
        "81": 8.720818519592285,
        "82": -5.820703983306885,
        "83": -16.344980239868164,
        "84": -1.1490085124969482,
        "85": 3.3335769176483154,
        "86": 4.824532985687256,
        "87": 9.369510650634766,
        "88": -2.879396677017212,
        "89": 6.448351860046387,
        "90": 2.4463107585906982,
        "91": -6.572671890258789,
        "92": -0.6030784845352173,
        "93": -3.0235297679901123,
        "94": -1.0547115802764893,
        "95": -1.525272011756897,
        "96": 9.374711990356445,
        "97": 7.493000030517578,
        "98": 2.2375967502593994,
        "99": 0.7291125655174255,
        "100": -6.108667850494385,
        "101": -3.0101070404052734,
        "102": -7.313798427581787,
        "103": -14.810918807983398,
        "104": 5.394396781921387,
        "105": -6.184727191925049,
        "106": 12.939922332763672,
        "107": 7.960082054138184,
        "108": 3.2182319164276123,
        "109": -1.8383277654647827,
        "110": 11.964808464050293,
        "111": -5.734161853790283,
        "112": 11.689663887023926,
        "113": -3.292600631713867,
        "114": 12.042181015014648,
        "115": -1.0081965923309326,
        "116": 5.861143589019775,
        "117": -15.451786994934082,
        "118": -2.093982696533203,
        "119": 2.25166916847229,
        "120": -14.903934478759766,
        "121": -1.546290397644043,
        "122": -3.018083095550537,
        "123": -3.1714727878570557,
        "124": -2.89169979095459,
        "125": -2.0923080444335938,
        "126": -5.396018981933594,
        "127": -4.901237487792969,
        "128": -5.711080074310303,
        "129": 5.867019176483154,
        "130": -6.691617488861084,
        "131": -4.464401721954346,
        "132": 2.7392475605010986,
        "133": -4.195598602294922,
        "134": -4.4540581703186035,
        "135": 6.450554370880127,
        "136": -2.6329777240753174,
        "137": -13.761943817138672,
        "138": -5.6159210205078125,
        "139": -2.626819372177124,
        "140": -5.377620697021484,
        "141": -7.816880226135254,
        "142": -7.15140438079834,
        "143": -2.377051591873169,
        "144": -13.124983787536621,
        "145": -4.574276924133301,
        "146": -3.307670831680298,
        "147": -5.4912109375,
        "148": -6.183438777923584,
        "149": -2.505988597869873,
        "150": -6.77587366104126,
        "151": -3.169442653656006,
        "152": -7.635269641876221,
        "153": -8.447100639343262,
        "154": -3.3927576541900635,
        "155": -9.314281463623047,
        "156": -6.659071445465088,
        "157": -2.8532662391662598,
        "158": -7.950139999389648,
        "159": -8.225873947143555,
        "160": -12.425358772277832,
        "161": -5.973855495452881,
        "162": -10.88770580291748,
        "163": -12.659811019897461,
        "164": -8.83174991607666,
        "165": -4.523264408111572,
        "166": -8.930571556091309,
        "167": -8.880267143249512,
        "168": -14.234748840332031,
        "169": -11.582930564880371,
        "170": 4.418745517730713,
        "171": -9.151681900024414,
        "172": -9.990888595581055,
        "173": -5.791092872619629,
        "174": -10.7524995803833,
        "175": -10.128262519836426,
        "176": -8.386225700378418,
        "177": -7.123635768890381,
        "178": -1.144102692604065,
        "179": -15.952624320983887,
        "180": 7.4367170333862305,
        "181": -2.2282299995422363,
        "182": -8.538134574890137,
        "183": -12.538572311401367,
        "184": -0.6406984329223633,
        "185": -9.40592098236084,
        "186": 2.874897003173828,
        "187": -1.3396427631378174,
        "188": -0.729709267616272,
        "189": -12.465585708618164,
        "190": 0.8415305018424988,
        "191": 7.663661003112793,
        "192": -11.604667663574219
    },
    "y": {
        "0": 0.9026404619216919,
        "1": -18.188814163208008,
        "2": 12.94645881652832,
        "3": -11.220732688903809,
        "4": 0.7290347814559937,
        "5": -2.5483055114746094,
        "6": 13.43036937713623,
        "7": -2.555908203125,
        "8": -18.31113624572754,
        "9": -4.155138969421387,
        "10": 6.093653202056885,
        "11": 0.23138561844825745,
        "12": -11.290224075317383,
        "13": 9.754379272460938,
        "14": -1.3667415380477905,
        "15": -6.245655059814453,
        "16": -12.627058982849121,
        "17": -15.196218490600586,
        "18": 3.212324380874634,
        "19": 9.592103958129883,
        "20": -21.032665252685547,
        "21": -11.05455493927002,
        "22": -6.2153706550598145,
        "23": 13.510030746459961,
        "24": -4.144508361816406,
        "25": -17.670032501220703,
        "26": -1.8688489198684692,
        "27": 9.503270149230957,
        "28": -12.381525039672852,
        "29": 4.7722859382629395,
        "30": 15.064167022705078,
        "31": 8.474325180053711,
        "32": -14.139881134033203,
        "33": 9.175938606262207,
        "34": 8.840950012207031,
        "35": -11.991576194763184,
        "36": -6.5367231369018555,
        "37": -0.9792978763580322,
        "38": -12.62210750579834,
        "39": -8.415371894836426,
        "40": 2.6463003158569336,
        "41": -5.903149127960205,
        "42": 5.278810501098633,
        "43": -7.24957275390625,
        "44": 3.7831006050109863,
        "45": -8.497892379760742,
        "46": 10.608194351196289,
        "47": -8.415024757385254,
        "48": -14.339552879333496,
        "49": -7.815732955932617,
        "50": -18.288543701171875,
        "51": 3.9002721309661865,
        "52": -0.34865596890449524,
        "53": -0.0848652794957161,
        "54": -7.409819602966309,
        "55": -11.90390396118164,
        "56": -9.98459243774414,
        "57": -16.357370376586914,
        "58": -7.768131732940674,
        "59": -4.8792033195495605,
        "60": 7.152194499969482,
        "61": 4.8573384284973145,
        "62": -0.7313656210899353,
        "63": -7.380167484283447,
        "64": -10.084418296813965,
        "65": 10.83054256439209,
        "66": 12.586891174316406,
        "67": -4.6642889976501465,
        "68": -6.848789691925049,
        "69": 9.551199913024902,
        "70": -15.056595802307129,
        "71": -12.47584342956543,
        "72": -11.34733772277832,
        "73": -7.9845404624938965,
        "74": -0.11743289977312088,
        "75": 3.109886646270752,
        "76": 4.377806186676025,
        "77": -10.145907402038574,
        "78": -7.538833141326904,
        "79": -7.339330196380615,
        "80": -12.719403266906738,
        "81": 0.3357185423374176,
        "82": 3.098127603530884,
        "83": -6.006811141967773,
        "84": -9.968328475952148,
        "85": -7.988768100738525,
        "86": 4.800814151763916,
        "87": 12.376359939575195,
        "88": -11.31746768951416,
        "89": 2.9079477787017822,
        "90": -5.83873987197876,
        "91": 4.879650115966797,
        "92": 11.400144577026367,
        "93": -4.749441146850586,
        "94": 10.3984375,
        "95": 10.616256713867188,
        "96": 12.400919914245605,
        "97": -9.973630905151367,
        "98": -11.29723072052002,
        "99": 10.269668579101562,
        "100": -16.257360458374023,
        "101": -5.649335861206055,
        "102": 4.223523139953613,
        "103": -6.231240749359131,
        "104": 8.215686798095703,
        "105": 3.091599464416504,
        "106": 5.83768892288208,
        "107": -10.694568634033203,
        "108": 8.457439422607422,
        "109": -4.841287136077881,
        "110": 5.4542012214660645,
        "111": -15.84753704071045,
        "112": 5.68959379196167,
        "113": 8.504433631896973,
        "114": 6.028433799743652,
        "115": -6.797088623046875,
        "116": 8.997110366821289,
        "117": -5.371087551116943,
        "118": -18.453672409057617,
        "119": -11.210787773132324,
        "120": -6.120224475860596,
        "121": -4.7996506690979,
        "122": -0.9586352705955505,
        "123": -15.660226821899414,
        "124": -14.780710220336914,
        "125": -18.437599182128906,
        "126": -20.142480850219727,
        "127": -16.47808074951172,
        "128": -17.600082397460938,
        "129": 10.990659713745117,
        "130": -3.6480894088745117,
        "131": -11.246850967407227,
        "132": -7.100876808166504,
        "133": -11.030805587768555,
        "134": 0.5407261252403259,
        "135": 10.209601402282715,
        "136": 10.606886863708496,
        "137": -14.61666202545166,
        "138": -20.23044204711914,
        "139": -15.605368614196777,
        "140": -14.45373249053955,
        "141": -16.56186866760254,
        "142": -13.950215339660645,
        "143": -14.04682731628418,
        "144": -13.67776107788086,
        "145": 0.4904489517211914,
        "146": -9.754592895507812,
        "147": -14.46986198425293,
        "148": -3.5357348918914795,
        "149": -3.9784510135650635,
        "150": -15.017799377441406,
        "151": -2.204427719116211,
        "152": -10.845708847045898,
        "153": -15.347832679748535,
        "154": -3.0234320163726807,
        "155": -16.512863159179688,
        "156": -4.163198947906494,
        "157": 1.937799334526062,
        "158": -1.8815877437591553,
        "159": -8.48071002960205,
        "160": -12.685050010681152,
        "161": -4.242956161499023,
        "162": -14.893342018127441,
        "163": -14.189742088317871,
        "164": -12.434176445007324,
        "165": -12.485114097595215,
        "166": -5.353030681610107,
        "167": -11.295912742614746,
        "168": -13.606731414794922,
        "169": -14.143877029418945,
        "170": 1.354844570159912,
        "171": -5.373971462249756,
        "172": -9.275611877441406,
        "173": -8.95313549041748,
        "174": -9.169310569763184,
        "175": -13.927638053894043,
        "176": -11.75378131866455,
        "177": -9.366957664489746,
        "178": 3.534006118774414,
        "179": -15.317405700683594,
        "180": 4.802056789398193,
        "181": 2.3643529415130615,
        "182": -7.778558254241943,
        "183": -15.045796394348145,
        "184": 1.2530980110168457,
        "185": -9.139236450195312,
        "186": -1.5389641523361206,
        "187": 0.178284153342247,
        "188": 1.7113723754882812,
        "189": -9.443589210510254,
        "190": 5.260815143585205,
        "191": 5.557145595550537,
        "192": -9.200054168701172
    },
    "title": {
        "0": "Author Correction: Prostate cancer therapy personalization via multi-modal deep learning on randomized phase III clinical trials",
        "1": "Large language models generate functional protein sequences across diverse families",
        "2": "The AI Economist: Taxation policy design via two-level deep multiagent reinforcement learning",
        "3": "Converse: A Tree-Based Modular Task-Oriented Dialogue System",
        "4": "Prostate cancer therapy personalization via multi-modal deep learning on randomized phase III clinical trials",
        "5": "Biological data annotation via a human-augmenting AI-based labeling system",
        "6": "The AI Economist: Optimal Economic Policy Design via Two-level Deep Reinforcement Learning",
        "7": "Biological data annotation via a human-augmenting AI-based labeling interface",
        "8": "Deep neural language modeling enables functional protein generation across families",
        "9": "COVID-19 information retrieval with deep-learning based semantic search, question answering, and abstractive summarization",
        "10": "Evaluating State-of-the-Art Classification Models Against Bayes Optimality",
        "11": "Deep learning-enabled medical computer vision",
        "12": "A Simple Language Model for Task-Oriented Dialogue",
        "13": "Explore, Discover and Learn: Unsupervised Discovery of State-Covering Skills",
        "14": "Dye-sensitized solar cells under ambient light powering machine learning: towards autonomous smart sensors for the internet of things\u2020",
        "15": "Photon: A Robust Cross-Domain Text-to-SQL System",
        "16": "Contextual Salience for Fast and Accurate Sentence Vectors.",
        "17": "GeDi: Generative Discriminator Guided Sequence Generation",
        "18": "Towards Noise-resistant Object Detection with Noisy Annotations",
        "19": "Taylorized Training: Towards Better Approximation of Neural Network Training at Finite Width",
        "20": "An Investigation of Phone-Based Subword Units for End-to-End Speech Recognition",
        "21": "Non-Autoregressive Dialog State Tracking",
        "22": "Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic Parsing",
        "23": "The AI Economist: Improving Equality and Productivity with AI-Driven Tax Policies",
        "24": "CO-Search: COVID-19 Information Retrieval with Semantic Search, Question Answering, and Abstractive Summarization",
        "25": "BERTology Meets Biology: Interpreting Attention in Protein Language Models",
        "26": "Explaining Creative Artifacts",
        "27": "Catastrophic Fisher Explosion: Early Phase Fisher Matrix Impacts Generalization",
        "28": "It\u2019s Morphin\u2019 Time! Combating Linguistic Discrimination with Inflectional Perturbations",
        "29": "WOAD: Weakly Supervised Online Action Detection in Untrimmed Videos",
        "30": "COVID-19 Growth Rate Decreases with Social Capital",
        "31": "Assessing Local Generalization Capability in Deep Models",
        "32": "Tree-structured Attention with Hierarchical Accumulation",
        "33": "Theory-Inspired Path-Regularized Differential Network Architecture Search",
        "34": "Towards Understanding Hierarchical Learning: Benefits of Neural Representations",
        "35": "TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue",
        "36": "Explicit Memory Tracker with Coarse-to-Fine Reasoning for Conversational Machine Reading",
        "37": "Artificial intelligence for streamlined immunofluorescence-based biomarker discovery in prostate cancer.",
        "38": "A High-Quality Multilingual Dataset for Structured Documentation Translation",
        "39": "DART: Open-Domain Structured Data Record to Text Generation",
        "40": "Improving out-of-distribution generalization via multi-task self-supervised pretraining",
        "41": "SummEval: Re-evaluating Summarization Evaluation",
        "42": "Neural Bayes: A Generic Parameterization Method for Unsupervised Representation Learning",
        "43": "GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing",
        "44": "Prototypical Contrastive Learning of Unsupervised Representations",
        "45": "Discriminative Nearest Neighbor Few-Shot Intent Detection by Transferring Natural Language Inference",
        "46": "Online Structured Meta-learning",
        "47": "Explaining and Improving Model Behavior with k Nearest Neighbor Representations",
        "48": "Optimal Feature Extraction based Machine Learning Approach for Sarcasm Type Detection in News Headlines",
        "49": "Composed Variational Natural Language Generation for Few-shot Intents",
        "50": "ProGen: Language Modeling for Protein Generation",
        "51": "DivideMix: Learning with Noisy Labels as Semi-supervised Learning",
        "52": "ESPRIT: Explaining Solutions to Physical Reasoning Tasks",
        "53": "Deep learning-enabled breast cancer hormonal receptor status determination from base-level H&E stains",
        "54": "Universal Natural Language Processing with Limited Annotations: Try Few-shot Textual Entailment as a Start",
        "55": "Central Yup'ik and Machine Translation of Low-Resource Polysynthetic Languages",
        "56": "Simple Data Augmentation with the Mask Token Improves Domain Adaptation for Dialog Act Tagging",
        "57": "Limits of Detecting Text Generated by Large-Scale Language Models",
        "58": "ERASER: A Benchmark to Evaluate Rationalized NLP Models",
        "59": "Evaluating the Factual Consistency of Abstractive Text Summarization",
        "60": "Global Capacity Measures for Deep ReLU Networks via Path Sampling",
        "61": "Self-Monitoring Navigation Agent via Auxiliary Progress Estimation",
        "62": "MP28-01\u2003ARTIFICIAL INTELLIGENCE (AI) ACCURATELY AUTOMATE AND SPEED IMMUNOFLUORESCENCE (IF)-BASED DISCOVERY AND VALIDATION OF NOVEL PROGNOSTIC AND PREDICTIVE BIOMARKERS IN PROSTATE CANCER",
        "63": "Unifying Question Answering, Text Classification, and Regression via Span Extraction",
        "64": "MKD: a Multi-Task Knowledge Distillation Approach for Pretrained Language Models",
        "65": "Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting",
        "66": "Pretrained AI Models: Performativity, Mobility, and Change",
        "67": "Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering",
        "68": "CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases",
        "69": "Learning World Graphs to Accelerate Hierarchical Reinforcement Learning",
        "70": "CTRL: A Conditional Transformer Language Model for Controllable Generation",
        "71": "Sketch-Fill-A-R: A Persona-Grounded Chit-Chat Generation Framework",
        "72": "Find or Classify? Dual Strategy for Slot-Value Predictions on Multi-Domain Dialog State Tracking",
        "73": "DESC LIMIT 1 LSTM Query Decoder Attention Over Previous Utterances , Column Headers , Previous Query Bi LSTM Query Encoder Table Encoder",
        "74": "Explain Yourself! Leveraging Language Models for Commonsense Reasoning",
        "75": "Learning From Noisy Anchors for One-Stage Object Detection",
        "76": "Predicting with High Correlation Features",
        "77": "Global-to-local Memory Pointer Networks for Task-Oriented Dialogue",
        "78": "Deleter: Leveraging BERT to Perform Unsupervised Successive Text Compression",
        "79": "Unifying Question Answering and Text Classification via Span Extraction",
        "80": "BERT is Not an Interlingua and the Bias of Tokenization",
        "81": "Automatic Classification of Cataract based on Deep Learnig",
        "82": "WSLLN:Weakly Supervised Natural Language Localization Networks",
        "83": "Neural Text Summarization: A Critical Evaluation",
        "84": "Attentive Student Meets Multi-Task Teacher: Improved Knowledge Distillation for Pretrained Models",
        "85": "Editing-Based SQL Query Generation for Cross-Domain Context-Dependent Questions",
        "86": "Entropy Penalty: Towards Generalization Beyond the IID Assumption",
        "87": "Private Deep Learning with Teacher Ensembles",
        "88": "XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and Question Answering",
        "89": "DIME: An Information-Theoretic Difficulty Measure for AI Datasets",
        "90": "SParC: Cross-Domain Semantic Parsing in Context",
        "91": "StartNet: Online Detection of Action Start in Untrimmed Videos",
        "92": "Taming MAML: Efficient unbiased meta-reinforcement learning",
        "93": "Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering",
        "94": "Keeping Your Distance: Solving Sparse Reward Tasks Using Self-Balancing Shaped Rewards",
        "95": "Competitive Experience Replay",
        "96": "Near-Zero-Cost Differentially Private Deep Learning with Teacher Ensembles",
        "97": "Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems",
        "98": "Genie: a generator of natural language semantic parsers for virtual assistant commands",
        "99": "On the Generalization Gap in Reparameterizable Reinforcement Learning",
        "100": "Scalable Language Modeling: WikiText-103 on a Single GPU in 12 hours",
        "101": "Efficient and Robust Question Answering from Minimal Context over Documents",
        "102": "AdaFrame: Adaptive Frame Selection for Fast Video Recognition",
        "103": "ODEL FOR A BSTRACTIVE S UMMARIZATION",
        "104": "Using Mode Connectivity for Loss Landscape Analysis",
        "105": "End-to-End Dense Video Captioning with Masked Transformer",
        "106": "A Multi-Discriminator CycleGAN for Unsupervised Non-Parallel Speech Domain Adaptation",
        "107": "Global-Locally Self-Attentive Encoder for Dialogue State Tracking",
        "108": "Identifying Generalization Properties in Neural Networks",
        "109": "BiLSTM 1 BiLSTM 1 Coattention 1 Coattention 2 BiLSTM 2 BiLSTM 2 Output BiLSTM Question Document",
        "110": "Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation",
        "111": "An Analysis of Neural Language Modeling at Multiple Scales",
        "112": "Augmented Cyclic Adversarial Learning for Domain Adaptation",
        "113": "Multi-Hop Knowledge Graph Reasoning with Reward Shaping",
        "114": "Robust Domain Adaptation By Augmented Cyclic Adversarial Learning",
        "115": "The Natural Language Decathlon: Multitask Learning as Question Answering",
        "116": "A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation",
        "117": "Improving Abstraction in Text Summarization",
        "118": "AUTOMATED RNN ARCHITECTURE GENERATION",
        "119": "Compositional Neural Semantic Parsing for Compound Virtual",
        "120": "A Deep Reinforced Model for Abstractive Summarization",
        "121": "DCN+: Mixed Objective and Deep Residual Coattention for Question Answering",
        "122": "Interpretable Counting for Visual Question Answering",
        "123": "Non-Autoregressive Neural Machine Translation",
        "124": "Weighted Transformer Network for Machine Translation",
        "125": "A Flexible Approach to Automated RNN Architecture Generation",
        "126": "Improving End-to-End Speech Recognition with Policy Learning",
        "127": "Regularizing and Optimizing LSTM Language Models",
        "128": "Revisiting Activation Regularization for Language RNNs",
        "129": "Improving Generalization Performance by Switching from Adam to SGD",
        "130": "2 Matching Text to Entities : Quiz Bowl",
        "131": "Learned in Translation: Contextualized Word Vectors",
        "132": "Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning",
        "133": "Towards the ImageNet-CNN of NLP: Pretraining Sentence Encoders with Machine Translation",
        "134": "Sentinel gate for modulating auxiliary information in a long short-term memory (LSTM) neural network",
        "135": "Block-diagonal Hessian-free Optimization for Training Neural Networks",
        "136": "Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning",
        "137": "Learning when to skim and when to read",
        "138": "Improved Regularization Techniques for End-to-End Speech Recognition",
        "139": "Towards Neural Machine Translation with Latent Tree Attention",
        "140": "BINING RECENT INSIGHTS FOR LSTMS",
        "141": "Quasi-Recurrent Neural Networks",
        "142": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling",
        "143": "MetaMind Neural Machine Translation System for WMT 2016",
        "144": "Deep Learning for Sentiment Analysis - Invited Talk",
        "145": "Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning",
        "146": "A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks",
        "147": "A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs",
        "148": "2 Matching Text to Entities : Quiz Bowl",
        "149": "Dynamic Coattention Networks For Question Answering",
        "150": "Pointer Sentinel Mixture Models",
        "151": "Dynamic Memory Networks for Visual and Textual Question Answering",
        "152": "CS 224D: Deep Learning for NLP",
        "153": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks",
        "154": "Ask Me Anything: Dynamic Memory Networks for Natural Language Processing",
        "155": "1 Recursive Neural Networks",
        "156": "2 Matching Text to Entities : Quiz Bowl",
        "157": "Grounded Compositional Semantics for Finding and Describing Images with Sentences",
        "158": "Scaling short-answer grading by combining peer assessment with algorithmic scoring",
        "159": "Recursive deep learning for natural language processing and computer vision",
        "160": "Aspect Specific Sentiment Analysis Using Hierarchical Deep Learning",
        "161": "A Neural Network for Factoid Question Answering over Paragraphs",
        "162": "Global Belief Recursive Neural Networks",
        "163": "Interactive Visualizations for Deep Learning",
        "164": "GloVe: Global Vectors for Word Representation",
        "165": "Bilingual Word Embeddings for Phrase-Based Machine Translation",
        "166": "Reasoning With Neural Tensor Networks for Knowledge Base Completion",
        "167": "Better Word Representations with Recursive Neural Networks for Morphology",
        "168": "Sentiment Analysis of Tweets : Baselines and Neural Network Models",
        "169": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
        "170": "Zero-Shot Learning Through Cross-Modal Transfer",
        "171": "Learning New Facts From Knowledge Bases With Neural Tensor Networks and Semantic Word Vectors",
        "172": "Parsing with Compositional Vector Grammars",
        "173": "Deep Learning for NLP (without Magic) References",
        "174": "Stanford \u2019 s System for Parsing the English Web",
        "175": "Semantic Compositionality through Recursive Matrix-Vector Spaces",
        "176": "Improving Word Representations via Global Context and Multiple Word Prototypes",
        "177": "Deep Learning for NLP (without Magic)",
        "178": "Convolutional-Recursive Deep Learning for 3D Object Classification",
        "179": "PREDICTING PREFERENCES Analyzing Reading Behavior and News Preferences",
        "180": "Spectral Chinese Restaurant Processes: Nonparametric Clustering Based on Similarities",
        "181": "Parsing Natural Scenes and Natural Language with Recursive Neural Networks",
        "182": "Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection",
        "183": "Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions",
        "184": "Connecting modalities: Semi-supervised segmentation and annotation of images using unaligned text corpora",
        "185": "Learning Continuous Phrase Representations and Syntactic Parsing with Recursive Neural Networks",
        "186": "A Bayesian Analysis of Dynamics in Free Recall",
        "187": "ImageNet: A large-scale hierarchical image database",
        "188": "Towards total scene understanding: Classification, annotation and segmentation in an automatic framework",
        "189": "Automatic Extension of Semantic Lexicons with a Bootstrapping Algorithm: Using Corpora to Learn Semantic Features",
        "190": "A learning based hierarchical model for vessel segmentation",
        "191": "Manifold Learning and Dimensionality Reduction with Diffusion Maps",
        "192": "Combining Contexts in Lexicon Learning for Semantic Parsing"
    },
    "year": {
        "0": 2023,
        "1": 2023,
        "2": 2022,
        "3": 2022,
        "4": 2022,
        "5": 2021,
        "6": 2021,
        "7": 2021,
        "8": 2021,
        "9": 2021,
        "10": 2021,
        "11": 2021,
        "12": 2020,
        "13": 2020,
        "14": 2020,
        "15": 2020,
        "16": 2020,
        "17": 2020,
        "18": 2020,
        "19": 2020,
        "20": 2020,
        "21": 2020,
        "22": 2020,
        "23": 2020,
        "24": 2020,
        "25": 2020,
        "26": 2020,
        "27": 2020,
        "28": 2020,
        "29": 2020,
        "30": 2020,
        "31": 2020,
        "32": 2020,
        "33": 2020,
        "34": 2020,
        "35": 2020,
        "36": 2020,
        "37": 2020,
        "38": 2020,
        "39": 2020,
        "40": 2020,
        "41": 2020,
        "42": 2020,
        "43": 2020,
        "44": 2020,
        "45": 2020,
        "46": 2020,
        "47": 2020,
        "48": 2020,
        "49": 2020,
        "50": 2020,
        "51": 2020,
        "52": 2020,
        "53": 2020,
        "54": 2020,
        "55": 2020,
        "56": 2020,
        "57": 2020,
        "58": 2019,
        "59": 2019,
        "60": 2019,
        "61": 2019,
        "62": 2019,
        "63": 2019,
        "64": 2019,
        "65": 2019,
        "66": 2019,
        "67": 2019,
        "68": 2019,
        "69": 2019,
        "70": 2019,
        "71": 2019,
        "72": 2019,
        "73": 2019,
        "74": 2019,
        "75": 2019,
        "76": 2019,
        "77": 2019,
        "78": 2019,
        "79": 2019,
        "80": 2019,
        "81": 2019,
        "82": 2019,
        "83": 2019,
        "84": 2019,
        "85": 2019,
        "86": 2019,
        "87": 2019,
        "88": 2019,
        "89": 2019,
        "90": 2019,
        "91": 2019,
        "92": 2019,
        "93": 2019,
        "94": 2019,
        "95": 2019,
        "96": 2019,
        "97": 2019,
        "98": 2019,
        "99": 2019,
        "100": 2018,
        "101": 2018,
        "102": 2018,
        "103": 2018,
        "104": 2018,
        "105": 2018,
        "106": 2018,
        "107": 2018,
        "108": 2018,
        "109": 2018,
        "110": 2018,
        "111": 2018,
        "112": 2018,
        "113": 2018,
        "114": 2018,
        "115": 2018,
        "116": 2018,
        "117": 2018,
        "118": 2018,
        "119": 2018,
        "120": 2017,
        "121": 2017,
        "122": 2017,
        "123": 2017,
        "124": 2017,
        "125": 2017,
        "126": 2017,
        "127": 2017,
        "128": 2017,
        "129": 2017,
        "130": 2017,
        "131": 2017,
        "132": 2017,
        "133": 2017,
        "134": 2017,
        "135": 2017,
        "136": 2017,
        "137": 2017,
        "138": 2017,
        "139": 2017,
        "140": 2016,
        "141": 2016,
        "142": 2016,
        "143": 2016,
        "144": 2016,
        "145": 2016,
        "146": 2016,
        "147": 2016,
        "148": 2016,
        "149": 2016,
        "150": 2016,
        "151": 2016,
        "152": 2015,
        "153": 2015,
        "154": 2015,
        "155": 2015,
        "156": 2015,
        "157": 2014,
        "158": 2014,
        "159": 2014,
        "160": 2014,
        "161": 2014,
        "162": 2014,
        "163": 2014,
        "164": 2014,
        "165": 2013,
        "166": 2013,
        "167": 2013,
        "168": 2013,
        "169": 2013,
        "170": 2013,
        "171": 2013,
        "172": 2013,
        "173": 2012,
        "174": 2012,
        "175": 2012,
        "176": 2012,
        "177": 2012,
        "178": 2012,
        "179": 2011,
        "180": 2011,
        "181": 2011,
        "182": 2011,
        "183": 2011,
        "184": 2010,
        "185": 2010,
        "186": 2009,
        "187": 2009,
        "188": 2009,
        "189": 2008,
        "190": 2008,
        "191": 2008,
        "192": 2007
    },
    "cluster": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 3,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 2,
        "10": 4,
        "11": 1,
        "12": 3,
        "13": 1,
        "14": 1,
        "15": 3,
        "16": 2,
        "17": 2,
        "18": 0,
        "19": 4,
        "20": 2,
        "21": 3,
        "22": 3,
        "23": 1,
        "24": 2,
        "25": 1,
        "26": 1,
        "27": 4,
        "28": 2,
        "29": 0,
        "30": 1,
        "31": 4,
        "32": 2,
        "33": 4,
        "34": 4,
        "35": 3,
        "36": 3,
        "37": 1,
        "38": 2,
        "39": 3,
        "40": 4,
        "41": 2,
        "42": 4,
        "43": 3,
        "44": 4,
        "45": 3,
        "46": 1,
        "47": 2,
        "48": 2,
        "49": 0,
        "50": 1,
        "51": 4,
        "52": 1,
        "53": 1,
        "54": 3,
        "55": 2,
        "56": 3,
        "57": 2,
        "58": 2,
        "59": 3,
        "60": 4,
        "61": 0,
        "62": 1,
        "63": 3,
        "64": 2,
        "65": 4,
        "66": 1,
        "67": 3,
        "68": 3,
        "69": 1,
        "70": 2,
        "71": 3,
        "72": 3,
        "73": 3,
        "74": 3,
        "75": 0,
        "76": 4,
        "77": 3,
        "78": 2,
        "79": 3,
        "80": 2,
        "81": 1,
        "82": 0,
        "83": 2,
        "84": 2,
        "85": 3,
        "86": 4,
        "87": 4,
        "88": 2,
        "89": 4,
        "90": 3,
        "91": 0,
        "92": 1,
        "93": 3,
        "94": 1,
        "95": 1,
        "96": 4,
        "97": 3,
        "98": 3,
        "99": 4,
        "100": 2,
        "101": 3,
        "102": 0,
        "103": 2,
        "104": 4,
        "105": 0,
        "106": 4,
        "107": 3,
        "108": 4,
        "109": 3,
        "110": 4,
        "111": 2,
        "112": 4,
        "113": 3,
        "114": 4,
        "115": 3,
        "116": 4,
        "117": 2,
        "118": 2,
        "119": 3,
        "120": 2,
        "121": 3,
        "122": 0,
        "123": 2,
        "124": 2,
        "125": 2,
        "126": 2,
        "127": 2,
        "128": 2,
        "129": 4,
        "130": 3,
        "131": 2,
        "132": 3,
        "133": 2,
        "134": 0,
        "135": 4,
        "136": 1,
        "137": 2,
        "138": 2,
        "139": 2,
        "140": 2,
        "141": 2,
        "142": 2,
        "143": 2,
        "144": 2,
        "145": 0,
        "146": 2,
        "147": 2,
        "148": 3,
        "149": 3,
        "150": 2,
        "151": 0,
        "152": 2,
        "153": 2,
        "154": 2,
        "155": 2,
        "156": 3,
        "157": 0,
        "158": 1,
        "159": 2,
        "160": 2,
        "161": 3,
        "162": 2,
        "163": 2,
        "164": 2,
        "165": 2,
        "166": 2,
        "167": 2,
        "168": 2,
        "169": 2,
        "170": 0,
        "171": 2,
        "172": 2,
        "173": 2,
        "174": 2,
        "175": 2,
        "176": 2,
        "177": 2,
        "178": 0,
        "179": 2,
        "180": 4,
        "181": 0,
        "182": 2,
        "183": 2,
        "184": 0,
        "185": 2,
        "186": 1,
        "187": 0,
        "188": 0,
        "189": 2,
        "190": 4,
        "191": 4,
        "192": 2
    },
    "authors": {
        "0": "A. Esteva, Jean Feng, D. van der Wal, Shih-Cheng Huang, J. Simko, et al.",
        "1": "Ali Madani, Ben Krause, E. Greene, Subu Subramanian, Benjamin P. Mohr, et al.",
        "2": "Stephan Zheng, Alexander R. Trott, Sunil Srinivasa, David C. Parkes, and R. Socher",
        "3": "Tian Xie, Xinyi Yang, Angela S. Lin, Feihong Wu, Kazuma Hashimoto, et al.",
        "4": "A. Esteva, Jean Feng, D. van der Wal, Shih-Cheng Huang, J. Simko, et al.",
        "5": "D. van der Wal, Iny Jhun, Israa Laklouk, Jeff Nirschl, Lara Richer, et al.",
        "6": "Stephan Zheng, Alexander R. Trott, Sunil Srinivasa, David C. Parkes, and R. Socher",
        "7": "A. Esteva, D. V. D. Wal, Iny Jhun, Israa Laklouk, Jeffrey J. Nirschl, et al.",
        "8": "Ali Madani, Ben Krause, E. Greene, Subu Subramanian, Benjamin P. Mohr, et al.",
        "9": "A. Esteva, Anuprit Kale, Romain Paulus, Kazuma Hashimoto, Wenpeng Yin, et al.",
        "10": "Ryan Theisen, Huan Wang, L. Varshney, Caiming Xiong, and R. Socher",
        "11": "A. Esteva, Katherine Chou, Serena Yeung, N. Naik, Ali Madani, et al.",
        "12": "Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, and R. Socher",
        "13": "V\u00edctor Campos, Alexander R. Trott, Caiming Xiong, R. Socher, Xavier Giro-i-Nieto, et al.",
        "14": "H. Michaels, M. Rinderle, Richard Freitag, Iacopo Benesperi, T. Edvinsson, et al.",
        "15": "Jichuan Zeng, Xi Victoria Lin, S. Hoi, R. Socher, Caiming Xiong, et al.",
        "16": "E. Zelikman and R. Socher",
        "17": "Ben Krause, Akhilesh Deepak Gotmare, Bryan McCann, N. Keskar, Shafiq R. Joty, et al.",
        "18": "Junnan Li, Caiming Xiong, R. Socher, and S. Hoi",
        "19": "Yu Bai, Ben Krause, Huan Wang, Caiming Xiong, and R. Socher",
        "20": "Weiran Wang, Yingbo Zhou, Caiming Xiong, and R. Socher",
        "21": "Hung Le, R. Socher, and S. Hoi",
        "22": "Xi Victoria Lin, R. Socher, and Caiming Xiong",
        "23": "Stephan Zheng, Alexander R. Trott, Sunil Srinivasa, N. Naik, Melvin Gruesbeck, et al.",
        "24": "A. Esteva, Anuprit Kale, Romain Paulus, Kazuma Hashimoto, Wenpeng Yin, et al.",
        "25": "Jesse Vig, Ali Madani, L. Varshney, Caiming Xiong, R. Socher, et al.",
        "26": "L. Varshney, Nazneen Rajani, and R. Socher",
        "27": "Stanislaw Jastrzebski, Devansh Arpit, Oliver \u00c5strand, Giancarlo Kerg, Huan Wang, et al.",
        "28": "Samson Tan, Shafiq R. Joty, Min-Yen Kan, and R. Socher",
        "29": "M. Gao, Yingbo Zhou, Ran Xu, R. Socher, and Caiming Xiong",
        "30": "L. Varshney and R. Socher",
        "31": "Huan Wang, N. Keskar, Caiming Xiong, and R. Socher",
        "32": "Xuan-Phi Nguyen, Shafiq R. Joty, S. Hoi, and R. Socher",
        "33": "Pan Zhou, Caiming Xiong, R. Socher, and S. Hoi",
        "34": "Minshuo Chen, Yu Bai, J. Lee, T. Zhao, Huan Wang, et al.",
        "35": "Chien-Sheng Wu, S. Hoi, R. Socher, and Caiming Xiong",
        "36": "Yifan Gao, Chien-Sheng Wu, Shafiq R. Joty, Caiming Xiong, R. Socher, et al.",
        "37": "C. Calle, Hao G Nguyen, Ehsan Hosseini-Asl, C. So, R. Socher, et al.",
        "38": "Kazuma Hashimoto, Raffaella Buschiazzo, James Bradbury, Teresa Marshall, R. Socher, et al.",
        "39": "Dragomir R. Radev, Rui Zhang, Amrit Rau, Abhinand Sivaprasad, Chia-Hsuan Hsieh, et al.",
        "40": "Isabela Albuquerque, N. Naik, Junnan Li, N. Keskar, and R. Socher",
        "41": "A. R. Fabbri, Wojciech Kryscinski, Bryan McCann, R. Socher, and Dragomir R. Radev",
        "42": "Devansh Arpit, Huan Wang, Caiming Xiong, R. Socher, and Yoshua Bengio",
        "43": "Tao Yu, Chien-Sheng Wu, Xi Victoria Lin, Bailin Wang, Y. Tan, et al.",
        "44": "Junnan Li, Pan Zhou, Caiming Xiong, R. Socher, and S. Hoi",
        "45": "Jianguo Zhang, Kazuma Hashimoto, Wenhao Liu, Chien-Sheng Wu, Yao Wan, et al.",
        "46": "Huaxiu Yao, Yingbo Zhou, M. Mahdavi, Z. Li, R. Socher, et al.",
        "47": "Nazneen Rajani, Ben Krause, Wengpeng Yin, Tong Niu, R. Socher, et al.",
        "48": "Vaishvi Prayag Jariwala, Mondher Bouazizi, Tomoaki Otsuki, Shuigui Huang, Wenwen Han, et al.",
        "49": "Congying Xia, Caiming Xiong, Philip S. Yu, and R. Socher",
        "50": "Ali Madani, Bryan McCann, N. Naik, N. Keskar, N. Anand, et al.",
        "51": "Junnan Li, R. Socher, and S. Hoi",
        "52": "Nazneen Rajani, Rui Zhang, Y. Tan, Stephan Zheng, Jeremy C. Weiss, et al.",
        "53": "N. Naik, Ali Madani, A. Esteva, N. Keskar, M. Press, et al.",
        "54": "Wenpeng Yin, Nazneen Rajani, Dragomir R. Radev, R. Socher, and Caiming Xiong",
        "55": "Christopher Liu, Laura Domin'e, Kevin Chavez, and R. Socher",
        "56": "Semih Yavuz, Kazuma Hashimoto, Wenhao Liu, N. Keskar, R. Socher, et al.",
        "57": "L. Varshney, N. Keskar, and R. Socher",
        "58": "Jay DeYoung, Sarthak Jain, Nazneen Rajani, Eric P. Lehman, Caiming Xiong, et al.",
        "59": "Wojciech Kryscinski, Bryan McCann, Caiming Xiong, and R. Socher",
        "60": "Ryan Theisen, Jason M. Klusowski, Huan Wang, N. Keskar, Caiming Xiong, et al.",
        "61": "Chih-Yao Ma, Jiasen Lu, Zuxuan Wu, G. Al-Regib, Z. Kira, et al.",
        "62": "Hao G Nguyen, Bogdana Schmidt, Ehsan Hosseini-Asl, C. So, R. Socher, et al.",
        "63": "N. Keskar, Bryan McCann, Caiming Xiong, and R. Socher",
        "64": "Linqing Liu, Haiquan Wang, Jimmy Lin, R. Socher, and Caiming Xiong",
        "65": "Xilai Li, Yingbo Zhou, Tianfu Wu, R. Socher, and Caiming Xiong",
        "66": "L. Varshney, N. Keskar, and R. Socher",
        "67": "Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, R. Socher, and Caiming Xiong",
        "68": "Tao Yu, Rui Zhang, H. Er, Suyi Li, Eric Xue, et al.",
        "69": "Wenling Shang, Alexander R. Trott, Stephan Zheng, Caiming Xiong, and R. Socher",
        "70": "N. Keskar, Bryan McCann, L. Varshney, Caiming Xiong, and R. Socher",
        "71": "Michael Shum, Stephan Zheng, Wojciech Kryscinski, Caiming Xiong, and R. Socher",
        "72": "Jianguo Zhang, Kazuma Hashimoto, Chien-Sheng Wu, Yao Wan, Philip S. Yu, et al.",
        "73": "Rui Zhang, Tao Yu, H. Er, Sungrok Shim, Eric Xue, et al.",
        "74": "Nazneen Rajani, Bryan McCann, Caiming Xiong, and R. Socher",
        "75": "Hengduo Li, Zuxuan Wu, Chen Zhu, Caiming Xiong, R. Socher, et al.",
        "76": "Devansh Arpit, Caiming Xiong, and R. Socher",
        "77": "Chien-Sheng Wu, R. Socher, and Caiming Xiong",
        "78": "Tong Niu, Caiming Xiong, and R. Socher",
        "79": "N. Keskar, Bryan McCann, Caiming Xiong, and R. Socher",
        "80": "Jasdeep Singh, Bryan McCann, R. Socher, and Caiming Xiong",
        "81": "Jingchao Sun, Lu Liu, M. Caixinha, E. Velte, M. Santos, et al.",
        "82": "M. Gao, L. Davis, R. Socher, and Caiming Xiong",
        "83": "Wojciech Kryscinski, N. Keskar, Bryan McCann, Caiming Xiong, and R. Socher",
        "84": "Linqing Liu, Haiquan Wang, Jimmy Lin, R. Socher, and Caiming Xiong",
        "85": "Rui Zhang, Tao Yu, H. Er, Sungrok Shim, Eric Xue, et al.",
        "86": "Devansh Arpit, Caiming Xiong, and R. Socher",
        "87": "Lichao Sun, Yingbo Zhou, Ji Wang, Jia Li, R. Socher, et al.",
        "88": "Jasdeep Singh, Bryan McCann, N. Keskar, Caiming Xiong, and R. Socher",
        "89": "Peiliang Zhang, Huan Wang, N. Naik, Caiming Xiong, and R. Socher",
        "90": "Tao Yu, Rui Zhang, Michihiro Yasunaga, Y. Tan, Xi Victoria Lin, et al.",
        "91": "M. Gao, Mingze Xu, L. Davis, R. Socher, and Caiming Xiong",
        "92": "Hao Liu, R. Socher, and Caiming Xiong",
        "93": "Victor Zhong, Caiming Xiong, N. Keskar, and R. Socher",
        "94": "Alexander R. Trott, Stephan Zheng, Caiming Xiong, and R. Socher",
        "95": "Hao Liu, Alexander R. Trott, R. Socher, and Caiming Xiong",
        "96": "Lichao Sun, Yingbo Zhou, Jia Li, R. Socher, Philip S. Yu, et al.",
        "97": "Chien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong, R. Socher, et al.",
        "98": "Giovanni Campagna, Silei Xu, M. Moradshahi, R. Socher, and M. Lam",
        "99": "Huan Wang, Stephan Zheng, Caiming Xiong, and R. Socher",
        "100": "Stephen Merity, N. Keskar, James Bradbury, and R. Socher",
        "101": "Sewon Min, Victor Zhong, R. Socher, and Caiming Xiong",
        "102": "Zuxuan Wu, Caiming Xiong, Chih-Yao Ma, R. Socher, and L. Davis",
        "103": "Romain Paulus, Caiming Xiong, and R. Socher",
        "104": "Akhilesh Deepak Gotmare, N. Keskar, Caiming Xiong, and R. Socher",
        "105": "Luowei Zhou, Yingbo Zhou, Jason J. Corso, R. Socher, and Caiming Xiong",
        "106": "Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, and R. Socher",
        "107": "Victor Zhong, Caiming Xiong, and R. Socher",
        "108": "Huan Wang, N. Keskar, Caiming Xiong, and R. Socher",
        "109": "Caiming Xiong, Victor Zhong, and R. Socher",
        "110": "Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, and R. Socher",
        "111": "Stephen Merity, N. Keskar, and R. Socher",
        "112": "Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, and R. Socher",
        "113": "Xi Victoria Lin, R. Socher, and Caiming Xiong",
        "114": "Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, and R. Socher",
        "115": "Bryan McCann, N. Keskar, Caiming Xiong, and R. Socher",
        "116": "Akhilesh Deepak Gotmare, N. Keskar, Caiming Xiong, and R. Socher",
        "117": "Wojciech Kryscinski, Romain Paulus, Caiming Xiong, and R. Socher",
        "118": "Stephen Merity, James Bradbury, and R. Socher",
        "119": "Giovanni Campagna, Silei Xu, R. Socher, and M. Lam",
        "120": "Romain Paulus, Caiming Xiong, and R. Socher",
        "121": "Caiming Xiong, Victor Zhong, and R. Socher",
        "122": "Alexander R. Trott, Caiming Xiong, and R. Socher",
        "123": "Jiatao Gu, James Bradbury, Caiming Xiong, V. Li, and R. Socher",
        "124": "Karim Ahmed, N. Keskar, and R. Socher",
        "125": "Martin Schrimpf, Stephen Merity, James Bradbury, and R. Socher",
        "126": "Yingbo Zhou, Caiming Xiong, and R. Socher",
        "127": "Stephen Merity, N. Keskar, and R. Socher",
        "128": "Stephen Merity, Bryan McCann, and R. Socher",
        "129": "N. Keskar and R. Socher",
        "130": "Mohit Iyyer, Jordan L. Boyd-Graber, L. Claudino, R. Socher, and Hal Daum\u00e9",
        "131": "Bryan McCann, James Bradbury, Caiming Xiong, and R. Socher",
        "132": "Victor Zhong, Caiming Xiong, and R. Socher",
        "133": "Bryan McCann, James Bradbury, Caiming Xiong, and R. Socher",
        "134": "Jiasen Lu, Caiming Xiong, and R. Socher",
        "135": "Huishuai Zhang, Caiming Xiong, James Bradbury, and R. Socher",
        "136": "Tianmin Shu, Caiming Xiong, and R. Socher",
        "137": "alexander rosenberg johansen and R. Socher",
        "138": "Yingbo Zhou, Caiming Xiong, and R. Socher",
        "139": "James Bradbury and R. Socher",
        "140": "S. Longpre, Sabeek Pradhan, Caiming Xiong, and R. Socher",
        "141": "James Bradbury, Stephen Merity, Caiming Xiong, and R. Socher",
        "142": "Hakan Inan, Khashayar Khosravi, and R. Socher",
        "143": "James Bradbury and R. Socher",
        "144": "R. Socher",
        "145": "Jiasen Lu, Caiming Xiong, Devi Parikh, and R. Socher",
        "146": "Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka, and R. Socher",
        "147": "S. Longpre, Sabeek Pradhan, Caiming Xiong, and R. Socher",
        "148": "Mohit Iyyer, Jordan L. Boyd-Graber, L. Claudino, R. Socher, and Hal Daum\u00e9",
        "149": "Caiming Xiong, Victor Zhong, and R. Socher",
        "150": "Stephen Merity, Caiming Xiong, James Bradbury, and R. Socher",
        "151": "Caiming Xiong, Stephen Merity, and R. Socher",
        "152": "R. Socher, Milad Mohammadi, and Rohit Mundra",
        "153": "Kai Sheng Tai, R. Socher, and Christopher D. Manning",
        "154": "A. Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, et al.",
        "155": "R. Socher and Francois Chaubard",
        "156": "Mohit Iyyer, Jordan L. Boyd-Graber, L. Claudino, R. Socher, and Hal Daum\u00e9",
        "157": "R. Socher, A. Karpathy, Quoc V. Le, Christopher D. Manning, and A. Ng",
        "158": "Chinmay Kulkarni, R. Socher, Michael S. Bernstein, and Scott R. Klemmer",
        "159": "R. Socher",
        "160": "Himabindu Lakkaraju, R. Socher, and Christopher D. Manning",
        "161": "Mohit Iyyer, Jordan L. Boyd-Graber, L. Claudino, R. Socher, and Hal Daum\u00e9",
        "162": "Romain Paulus, R. Socher, and Christopher D. Manning",
        "163": "Jason Chuang and R. Socher",
        "164": "Jeffrey Pennington, R. Socher, and Christopher D. Manning",
        "165": "Will Y. Zou, R. Socher, Daniel Matthew Cer, and Christopher D. Manning",
        "166": "R. Socher, Danqi Chen, Christopher D. Manning, and A. Ng",
        "167": "Thang Luong, R. Socher, and Christopher D. Manning",
        "168": "Kai Sheng Tai and R. Socher",
        "169": "R. Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, et al.",
        "170": "R. Socher, M. Ganjoo, Christopher D. Manning, and A. Ng",
        "171": "Danqi Chen, R. Socher, Christopher D. Manning, and A. Ng",
        "172": "R. Socher, John Bauer, Christopher D. Manning, and A. Ng",
        "173": "R. Socher, Yoshua Bengio, and Christopher D. Manning",
        "174": "David McClosky, Wanxiang Che, Marta Recasens, Mengqiu Wang, R. Socher, et al.",
        "175": "R. Socher, Brody Huval, Christopher D. Manning, and A. Ng",
        "176": "E. Huang, R. Socher, Christopher D. Manning, and A. Ng",
        "177": "R. Socher, Yoshua Bengio, and Christopher D. Manning",
        "178": "R. Socher, Brody Huval, Bharath Putta Bath, Christopher D. Manning, and A. Ng",
        "179": "Soravis Srinawakoon, Potcharapol Suteparuk, Advised, and R. Socher",
        "180": "R. Socher, Andrew L. Maas, and Christopher D. Manning",
        "181": "R. Socher, Cliff Chiung-Yu Lin, A. Ng, and Christopher D. Manning",
        "182": "R. Socher, E. Huang, Jeffrey Pennington, A. Ng, and Christopher D. Manning",
        "183": "R. Socher, Jeffrey Pennington, E. Huang, A. Ng, and Christopher D. Manning",
        "184": "R. Socher and Li Fei-Fei",
        "185": "R. Socher, Christopher D. Manning, and A. Ng",
        "186": "R. Socher, S. Gershman, A. Perotte, P. Sederberg, D. Blei, et al.",
        "187": "Jia Deng, Wei Dong, R. Socher, Li-Jia Li, K. Li, et al.",
        "188": "Li-Jia Li, R. Socher, and Li Fei-Fei",
        "189": "R. Socher",
        "190": "R. Socher, Adrian Barbu, and D. Comaniciu",
        "191": "R. Socher",
        "192": "R. Socher, Chris Biemann, and Rainer Osswald"
    },
    "first_author": {
        "0": false,
        "1": false,
        "2": false,
        "3": false,
        "4": false,
        "5": false,
        "6": false,
        "7": false,
        "8": false,
        "9": false,
        "10": false,
        "11": false,
        "12": false,
        "13": false,
        "14": false,
        "15": false,
        "16": false,
        "17": false,
        "18": false,
        "19": false,
        "20": false,
        "21": false,
        "22": false,
        "23": false,
        "24": false,
        "25": false,
        "26": false,
        "27": false,
        "28": false,
        "29": false,
        "30": false,
        "31": false,
        "32": false,
        "33": false,
        "34": false,
        "35": false,
        "36": false,
        "37": false,
        "38": false,
        "39": false,
        "40": false,
        "41": false,
        "42": false,
        "43": false,
        "44": false,
        "45": false,
        "46": false,
        "47": false,
        "48": false,
        "49": false,
        "50": false,
        "51": false,
        "52": false,
        "53": false,
        "54": false,
        "55": false,
        "56": false,
        "57": false,
        "58": false,
        "59": false,
        "60": false,
        "61": false,
        "62": false,
        "63": false,
        "64": false,
        "65": false,
        "66": false,
        "67": false,
        "68": false,
        "69": false,
        "70": false,
        "71": false,
        "72": false,
        "73": false,
        "74": false,
        "75": false,
        "76": false,
        "77": false,
        "78": false,
        "79": false,
        "80": false,
        "81": false,
        "82": false,
        "83": false,
        "84": false,
        "85": false,
        "86": false,
        "87": false,
        "88": false,
        "89": false,
        "90": false,
        "91": false,
        "92": false,
        "93": false,
        "94": false,
        "95": false,
        "96": false,
        "97": false,
        "98": false,
        "99": false,
        "100": false,
        "101": false,
        "102": false,
        "103": false,
        "104": false,
        "105": false,
        "106": false,
        "107": false,
        "108": false,
        "109": false,
        "110": false,
        "111": false,
        "112": false,
        "113": false,
        "114": false,
        "115": false,
        "116": false,
        "117": false,
        "118": false,
        "119": false,
        "120": false,
        "121": false,
        "122": false,
        "123": false,
        "124": false,
        "125": false,
        "126": false,
        "127": false,
        "128": false,
        "129": false,
        "130": false,
        "131": false,
        "132": false,
        "133": false,
        "134": false,
        "135": false,
        "136": false,
        "137": false,
        "138": false,
        "139": false,
        "140": false,
        "141": false,
        "142": false,
        "143": false,
        "144": true,
        "145": false,
        "146": false,
        "147": false,
        "148": false,
        "149": false,
        "150": false,
        "151": false,
        "152": true,
        "153": false,
        "154": false,
        "155": true,
        "156": false,
        "157": true,
        "158": false,
        "159": true,
        "160": false,
        "161": false,
        "162": false,
        "163": false,
        "164": false,
        "165": false,
        "166": true,
        "167": false,
        "168": false,
        "169": true,
        "170": true,
        "171": false,
        "172": true,
        "173": true,
        "174": false,
        "175": true,
        "176": false,
        "177": true,
        "178": true,
        "179": false,
        "180": true,
        "181": true,
        "182": true,
        "183": true,
        "184": true,
        "185": true,
        "186": true,
        "187": false,
        "188": false,
        "189": true,
        "190": true,
        "191": true,
        "192": true
    },
    "last_author": {
        "0": false,
        "1": false,
        "2": true,
        "3": false,
        "4": false,
        "5": false,
        "6": true,
        "7": true,
        "8": false,
        "9": true,
        "10": true,
        "11": true,
        "12": true,
        "13": false,
        "14": false,
        "15": false,
        "16": true,
        "17": false,
        "18": false,
        "19": true,
        "20": true,
        "21": false,
        "22": false,
        "23": true,
        "24": true,
        "25": false,
        "26": true,
        "27": false,
        "28": true,
        "29": false,
        "30": true,
        "31": true,
        "32": true,
        "33": false,
        "34": true,
        "35": false,
        "36": false,
        "37": false,
        "38": false,
        "39": true,
        "40": true,
        "41": false,
        "42": false,
        "43": false,
        "44": false,
        "45": false,
        "46": false,
        "47": false,
        "48": false,
        "49": true,
        "50": true,
        "51": false,
        "52": false,
        "53": true,
        "54": false,
        "55": true,
        "56": false,
        "57": true,
        "58": false,
        "59": true,
        "60": true,
        "61": false,
        "62": false,
        "63": true,
        "64": false,
        "65": false,
        "66": true,
        "67": false,
        "68": false,
        "69": true,
        "70": true,
        "71": true,
        "72": false,
        "73": false,
        "74": true,
        "75": false,
        "76": true,
        "77": false,
        "78": true,
        "79": true,
        "80": false,
        "81": false,
        "82": false,
        "83": true,
        "84": false,
        "85": false,
        "86": true,
        "87": false,
        "88": true,
        "89": true,
        "90": false,
        "91": false,
        "92": false,
        "93": true,
        "94": true,
        "95": false,
        "96": false,
        "97": false,
        "98": false,
        "99": true,
        "100": true,
        "101": false,
        "102": false,
        "103": true,
        "104": true,
        "105": false,
        "106": true,
        "107": true,
        "108": true,
        "109": true,
        "110": true,
        "111": true,
        "112": true,
        "113": false,
        "114": true,
        "115": true,
        "116": true,
        "117": true,
        "118": true,
        "119": false,
        "120": true,
        "121": true,
        "122": true,
        "123": true,
        "124": true,
        "125": true,
        "126": true,
        "127": true,
        "128": true,
        "129": true,
        "130": false,
        "131": true,
        "132": true,
        "133": true,
        "134": true,
        "135": true,
        "136": true,
        "137": true,
        "138": true,
        "139": true,
        "140": true,
        "141": true,
        "142": true,
        "143": true,
        "144": false,
        "145": true,
        "146": true,
        "147": true,
        "148": false,
        "149": true,
        "150": true,
        "151": true,
        "152": false,
        "153": false,
        "154": true,
        "155": false,
        "156": false,
        "157": false,
        "158": false,
        "159": false,
        "160": false,
        "161": false,
        "162": false,
        "163": true,
        "164": false,
        "165": false,
        "166": false,
        "167": false,
        "168": true,
        "169": false,
        "170": false,
        "171": false,
        "172": false,
        "173": false,
        "174": false,
        "175": false,
        "176": false,
        "177": false,
        "178": false,
        "179": true,
        "180": false,
        "181": false,
        "182": false,
        "183": false,
        "184": false,
        "185": false,
        "186": false,
        "187": false,
        "188": false,
        "189": false,
        "190": false,
        "191": false,
        "192": false
    },
    "middle_author": {
        "0": true,
        "1": true,
        "2": false,
        "3": true,
        "4": true,
        "5": true,
        "6": false,
        "7": false,
        "8": true,
        "9": false,
        "10": false,
        "11": false,
        "12": false,
        "13": true,
        "14": true,
        "15": true,
        "16": false,
        "17": true,
        "18": true,
        "19": false,
        "20": false,
        "21": true,
        "22": true,
        "23": false,
        "24": false,
        "25": true,
        "26": false,
        "27": true,
        "28": false,
        "29": true,
        "30": false,
        "31": false,
        "32": false,
        "33": true,
        "34": false,
        "35": true,
        "36": true,
        "37": true,
        "38": true,
        "39": false,
        "40": false,
        "41": true,
        "42": true,
        "43": true,
        "44": true,
        "45": true,
        "46": true,
        "47": true,
        "48": true,
        "49": false,
        "50": false,
        "51": true,
        "52": true,
        "53": false,
        "54": true,
        "55": false,
        "56": true,
        "57": false,
        "58": true,
        "59": false,
        "60": false,
        "61": true,
        "62": true,
        "63": false,
        "64": true,
        "65": true,
        "66": false,
        "67": true,
        "68": true,
        "69": false,
        "70": false,
        "71": false,
        "72": true,
        "73": true,
        "74": false,
        "75": true,
        "76": false,
        "77": true,
        "78": false,
        "79": false,
        "80": true,
        "81": true,
        "82": true,
        "83": false,
        "84": true,
        "85": true,
        "86": false,
        "87": true,
        "88": false,
        "89": false,
        "90": true,
        "91": true,
        "92": true,
        "93": false,
        "94": false,
        "95": true,
        "96": true,
        "97": true,
        "98": true,
        "99": false,
        "100": false,
        "101": true,
        "102": true,
        "103": false,
        "104": false,
        "105": true,
        "106": false,
        "107": false,
        "108": false,
        "109": false,
        "110": false,
        "111": false,
        "112": false,
        "113": true,
        "114": false,
        "115": false,
        "116": false,
        "117": false,
        "118": false,
        "119": true,
        "120": false,
        "121": false,
        "122": false,
        "123": false,
        "124": false,
        "125": false,
        "126": false,
        "127": false,
        "128": false,
        "129": false,
        "130": true,
        "131": false,
        "132": false,
        "133": false,
        "134": false,
        "135": false,
        "136": false,
        "137": false,
        "138": false,
        "139": false,
        "140": false,
        "141": false,
        "142": false,
        "143": false,
        "144": false,
        "145": false,
        "146": false,
        "147": false,
        "148": true,
        "149": false,
        "150": false,
        "151": false,
        "152": false,
        "153": true,
        "154": false,
        "155": false,
        "156": true,
        "157": false,
        "158": true,
        "159": false,
        "160": true,
        "161": true,
        "162": true,
        "163": false,
        "164": true,
        "165": true,
        "166": false,
        "167": true,
        "168": false,
        "169": false,
        "170": false,
        "171": true,
        "172": false,
        "173": false,
        "174": true,
        "175": false,
        "176": true,
        "177": false,
        "178": false,
        "179": false,
        "180": false,
        "181": false,
        "182": false,
        "183": false,
        "184": false,
        "185": false,
        "186": false,
        "187": true,
        "188": true,
        "189": false,
        "190": false,
        "191": false,
        "192": false
    },
    "author_of_interest": {
        "0": "R. Socher",
        "1": "R. Socher",
        "2": "R. Socher",
        "3": "R. Socher",
        "4": "R. Socher",
        "5": "R. Socher",
        "6": "R. Socher",
        "7": "R. Socher",
        "8": "R. Socher",
        "9": "R. Socher",
        "10": "R. Socher",
        "11": "R. Socher",
        "12": "R. Socher",
        "13": "R. Socher",
        "14": "R. Socher",
        "15": "R. Socher",
        "16": "R. Socher",
        "17": "R. Socher",
        "18": "R. Socher",
        "19": "R. Socher",
        "20": "R. Socher",
        "21": "R. Socher",
        "22": "R. Socher",
        "23": "R. Socher",
        "24": "R. Socher",
        "25": "R. Socher",
        "26": "R. Socher",
        "27": "R. Socher",
        "28": "R. Socher",
        "29": "R. Socher",
        "30": "R. Socher",
        "31": "R. Socher",
        "32": "R. Socher",
        "33": "R. Socher",
        "34": "R. Socher",
        "35": "R. Socher",
        "36": "R. Socher",
        "37": "R. Socher",
        "38": "R. Socher",
        "39": "R. Socher",
        "40": "R. Socher",
        "41": "R. Socher",
        "42": "R. Socher",
        "43": "R. Socher",
        "44": "R. Socher",
        "45": "R. Socher",
        "46": "R. Socher",
        "47": "R. Socher",
        "48": "R. Socher",
        "49": "R. Socher",
        "50": "R. Socher",
        "51": "R. Socher",
        "52": "R. Socher",
        "53": "R. Socher",
        "54": "R. Socher",
        "55": "R. Socher",
        "56": "R. Socher",
        "57": "R. Socher",
        "58": "R. Socher",
        "59": "R. Socher",
        "60": "R. Socher",
        "61": "R. Socher",
        "62": "R. Socher",
        "63": "R. Socher",
        "64": "R. Socher",
        "65": "R. Socher",
        "66": "R. Socher",
        "67": "R. Socher",
        "68": "R. Socher",
        "69": "R. Socher",
        "70": "R. Socher",
        "71": "R. Socher",
        "72": "R. Socher",
        "73": "R. Socher",
        "74": "R. Socher",
        "75": "R. Socher",
        "76": "R. Socher",
        "77": "R. Socher",
        "78": "R. Socher",
        "79": "R. Socher",
        "80": "R. Socher",
        "81": "R. Socher",
        "82": "R. Socher",
        "83": "R. Socher",
        "84": "R. Socher",
        "85": "R. Socher",
        "86": "R. Socher",
        "87": "R. Socher",
        "88": "R. Socher",
        "89": "R. Socher",
        "90": "R. Socher",
        "91": "R. Socher",
        "92": "R. Socher",
        "93": "R. Socher",
        "94": "R. Socher",
        "95": "R. Socher",
        "96": "R. Socher",
        "97": "R. Socher",
        "98": "R. Socher",
        "99": "R. Socher",
        "100": "R. Socher",
        "101": "R. Socher",
        "102": "R. Socher",
        "103": "R. Socher",
        "104": "R. Socher",
        "105": "R. Socher",
        "106": "R. Socher",
        "107": "R. Socher",
        "108": "R. Socher",
        "109": "R. Socher",
        "110": "R. Socher",
        "111": "R. Socher",
        "112": "R. Socher",
        "113": "R. Socher",
        "114": "R. Socher",
        "115": "R. Socher",
        "116": "R. Socher",
        "117": "R. Socher",
        "118": "R. Socher",
        "119": "R. Socher",
        "120": "R. Socher",
        "121": "R. Socher",
        "122": "R. Socher",
        "123": "R. Socher",
        "124": "R. Socher",
        "125": "R. Socher",
        "126": "R. Socher",
        "127": "R. Socher",
        "128": "R. Socher",
        "129": "R. Socher",
        "130": "R. Socher",
        "131": "R. Socher",
        "132": "R. Socher",
        "133": "R. Socher",
        "134": "R. Socher",
        "135": "R. Socher",
        "136": "R. Socher",
        "137": "R. Socher",
        "138": "R. Socher",
        "139": "R. Socher",
        "140": "R. Socher",
        "141": "R. Socher",
        "142": "R. Socher",
        "143": "R. Socher",
        "144": "R. Socher",
        "145": "R. Socher",
        "146": "R. Socher",
        "147": "R. Socher",
        "148": "R. Socher",
        "149": "R. Socher",
        "150": "R. Socher",
        "151": "R. Socher",
        "152": "R. Socher",
        "153": "R. Socher",
        "154": "R. Socher",
        "155": "R. Socher",
        "156": "R. Socher",
        "157": "R. Socher",
        "158": "R. Socher",
        "159": "R. Socher",
        "160": "R. Socher",
        "161": "R. Socher",
        "162": "R. Socher",
        "163": "R. Socher",
        "164": "R. Socher",
        "165": "R. Socher",
        "166": "R. Socher",
        "167": "R. Socher",
        "168": "R. Socher",
        "169": "R. Socher",
        "170": "R. Socher",
        "171": "R. Socher",
        "172": "R. Socher",
        "173": "R. Socher",
        "174": "R. Socher",
        "175": "R. Socher",
        "176": "R. Socher",
        "177": "R. Socher",
        "178": "R. Socher",
        "179": "R. Socher",
        "180": "R. Socher",
        "181": "R. Socher",
        "182": "R. Socher",
        "183": "R. Socher",
        "184": "R. Socher",
        "185": "R. Socher",
        "186": "R. Socher",
        "187": "R. Socher",
        "188": "R. Socher",
        "189": "R. Socher",
        "190": "R. Socher",
        "191": "R. Socher",
        "192": "R. Socher"
    },
    "reference_count": {
        "0": 0,
        "1": 98,
        "2": 21,
        "3": 16,
        "4": 43,
        "5": 31,
        "6": 12,
        "7": 31,
        "8": 75,
        "9": 49,
        "10": 39,
        "11": 170,
        "12": 69,
        "13": 78,
        "14": 59,
        "15": 51,
        "16": 16,
        "17": 65,
        "18": 52,
        "19": 42,
        "20": 44,
        "21": 44,
        "22": 67,
        "23": 98,
        "24": 29,
        "25": 105,
        "26": 65,
        "27": 87,
        "28": 54,
        "29": 33,
        "30": 29,
        "31": 43,
        "32": 29,
        "33": 55,
        "34": 55,
        "35": 50,
        "36": 31,
        "37": 0,
        "38": 35,
        "39": 103,
        "40": 45,
        "41": 90,
        "42": 38,
        "43": 65,
        "44": 60,
        "45": 60,
        "46": 43,
        "47": 41,
        "48": 20,
        "49": 36,
        "50": 52,
        "51": 46,
        "52": 68,
        "53": 45,
        "54": 36,
        "55": 10,
        "56": 36,
        "57": 39,
        "58": 76,
        "59": 56,
        "60": 29,
        "61": 57,
        "62": 0,
        "63": 30,
        "64": 47,
        "65": 31,
        "66": 100,
        "67": 48,
        "68": 62,
        "69": 99,
        "70": 91,
        "71": 47,
        "72": 44,
        "73": 54,
        "74": 28,
        "75": 44,
        "76": 42,
        "77": 40,
        "78": 22,
        "79": 37,
        "80": 31,
        "81": 22,
        "82": 40,
        "83": 80,
        "84": 45,
        "85": 54,
        "86": 42,
        "87": 33,
        "88": 31,
        "89": 19,
        "90": 45,
        "91": 39,
        "92": 0,
        "93": 58,
        "94": 36,
        "95": 55,
        "96": 36,
        "97": 52,
        "98": 78,
        "99": 62,
        "100": 15,
        "101": 43,
        "102": 40,
        "103": 39,
        "104": 20,
        "105": 44,
        "106": 39,
        "107": 41,
        "108": 36,
        "109": 30,
        "110": 49,
        "111": 35,
        "112": 49,
        "113": 35,
        "114": 35,
        "115": 132,
        "116": 39,
        "117": 36,
        "118": 34,
        "119": 47,
        "120": 43,
        "121": 32,
        "122": 49,
        "123": 32,
        "124": 36,
        "125": 44,
        "126": 30,
        "127": 47,
        "128": 33,
        "129": 31,
        "130": 35,
        "131": 73,
        "132": 44,
        "133": 0,
        "134": 0,
        "135": 44,
        "136": 32,
        "137": 22,
        "138": 28,
        "139": 26,
        "140": 28,
        "141": 39,
        "142": 34,
        "143": 15,
        "144": 0,
        "145": 37,
        "146": 57,
        "147": 30,
        "148": 35,
        "149": 32,
        "150": 29,
        "151": 43,
        "152": 0,
        "153": 42,
        "154": 52,
        "155": 0,
        "156": 35,
        "157": 52,
        "158": 34,
        "159": 120,
        "160": 18,
        "161": 35,
        "162": 30,
        "163": 9,
        "164": 32,
        "165": 42,
        "166": 25,
        "167": 38,
        "168": 16,
        "169": 49,
        "170": 36,
        "171": 15,
        "172": 43,
        "173": 77,
        "174": 18,
        "175": 44,
        "176": 39,
        "177": 2,
        "178": 32,
        "179": 9,
        "180": 30,
        "181": 25,
        "182": 28,
        "183": 41,
        "184": 24,
        "185": 18,
        "186": 20,
        "187": 27,
        "188": 32,
        "189": 79,
        "190": 67,
        "191": 10,
        "192": 16
    },
    "citation_count": {
        "0": 0,
        "1": 126,
        "2": 32,
        "3": 7,
        "4": 24,
        "5": 11,
        "6": 19,
        "7": 1,
        "8": 47,
        "9": 53,
        "10": 3,
        "11": 393,
        "12": 371,
        "13": 102,
        "14": 112,
        "15": 44,
        "16": 0,
        "17": 233,
        "18": 20,
        "19": 22,
        "20": 34,
        "21": 42,
        "22": 127,
        "23": 108,
        "24": 56,
        "25": 188,
        "26": 2,
        "27": 42,
        "28": 81,
        "29": 24,
        "30": 26,
        "31": 1,
        "32": 63,
        "33": 46,
        "34": 36,
        "35": 236,
        "36": 17,
        "37": 5,
        "38": 12,
        "39": 125,
        "40": 30,
        "41": 350,
        "42": 1,
        "43": 165,
        "44": 609,
        "45": 62,
        "46": 27,
        "47": 22,
        "48": 4,
        "49": 27,
        "50": 194,
        "51": 600,
        "52": 13,
        "53": 120,
        "54": 59,
        "55": 0,
        "56": 3,
        "57": 10,
        "58": 419,
        "59": 448,
        "60": 3,
        "61": 220,
        "62": 0,
        "63": 32,
        "64": 19,
        "65": 272,
        "66": 14,
        "67": 232,
        "68": 151,
        "69": 17,
        "70": 850,
        "71": 8,
        "72": 145,
        "73": 0,
        "74": 375,
        "75": 70,
        "76": 7,
        "77": 137,
        "78": 6,
        "79": 19,
        "80": 65,
        "81": 0,
        "82": 57,
        "83": 279,
        "84": 18,
        "85": 115,
        "86": 1,
        "87": 2,
        "88": 73,
        "89": 4,
        "90": 125,
        "91": 37,
        "92": 71,
        "93": 56,
        "94": 65,
        "95": 43,
        "96": 0,
        "97": 348,
        "98": 56,
        "99": 27,
        "100": 3,
        "101": 151,
        "102": 145,
        "103": 0,
        "104": 19,
        "105": 421,
        "106": 51,
        "107": 176,
        "108": 45,
        "109": 0,
        "110": 46,
        "111": 164,
        "112": 12,
        "113": 255,
        "114": 0,
        "115": 557,
        "116": 180,
        "117": 121,
        "118": 0,
        "119": 1,
        "120": 1334,
        "121": 97,
        "122": 55,
        "123": 571,
        "124": 116,
        "125": 15,
        "126": 39,
        "127": 1000,
        "128": 38,
        "129": 407,
        "130": 0,
        "131": 842,
        "132": 797,
        "133": 3,
        "134": 2,
        "135": 16,
        "136": 122,
        "137": 11,
        "138": 16,
        "139": 14,
        "140": 1,
        "141": 370,
        "142": 355,
        "143": 16,
        "144": 4,
        "145": 1236,
        "146": 530,
        "147": 8,
        "148": 0,
        "149": 649,
        "150": 1556,
        "151": 721,
        "152": 11,
        "153": 2890,
        "154": 1132,
        "155": 0,
        "156": 0,
        "157": 859,
        "158": 95,
        "159": 77,
        "160": 95,
        "161": 342,
        "162": 48,
        "163": 4,
        "164": 27848,
        "165": 564,
        "166": 1798,
        "167": 853,
        "168": 1,
        "169": 6732,
        "170": 1338,
        "171": 62,
        "172": 952,
        "173": 1,
        "174": 4,
        "175": 1342,
        "176": 1240,
        "177": 165,
        "178": 631,
        "179": 0,
        "180": 40,
        "181": 1394,
        "182": 937,
        "183": 1292,
        "184": 237,
        "185": 323,
        "186": 31,
        "187": 47379,
        "188": 548,
        "189": 0,
        "190": 22,
        "191": 12,
        "192": 2
    },
    "tldr": {
        "0": "In the interest of transparency and clinical relevance, the evaluation<br>of model performance in the validation set after removing any<br>cases with post-treatment prostate tissue is repeated, which results in<br>a slightly smaller cohort for validation, compared to the 20%<br>validation set used in the original paper.",
        "1": "ProGen is described, a language model that can generate protein<br>sequences with a predictable function across large protein families, akin<br>to generating grammatically and semantically correct natural language sentences on<br>diverse topics.",
        "2": "",
        "3": "Converse is a flexible tree-based modular task-oriented dialogue system that<br>uses an and-or tree structure to represent tasks and offers<br>powerful multi-task dialogue management and task dependency and task switching.",
        "4": "This artificial intelligence-based tool improves prognostication over standard tools and<br>allows oncologists to computationally predict the likeliest outcomes of specific<br>patients to determine optimal treatment.",
        "5": "HALS (Human-Augmenting Labeling System), a human-in-the-loop data labeling AI, which<br>begins uninitialized and learns annotations from a human, in real-time<br>is presented.",
        "6": "It is demonstrated for the first time that two-level, deep<br>RL can be used for understanding and as a complement<br>to theory for economic design, unlocking a new computational learning-based<br>approach to understanding economic policy.",
        "7": "HALI (Human-Augmenting Labeling Interface), a human-in-the-loop AI-based data labeling tool<br>which begins un-initialized and learns annotations from a human, in<br>real-time, increases both the efficiency of the annotator, and the<br>quality of the annotations.",
        "8": "It is demonstrated that a deep learning-based language model can<br>generate functional artificial protein sequences across families, akin to generating<br>grammatically and semantically correct natural language sentences on diverse topics.",
        "9": "CO-Search is presented, a semantic, multi-stage, search engine designed to<br>handle complex queries over the COVID-19 literature, potentially aiding overburdened<br>health workers in finding scientific answers and avoiding misinformation during<br>a time of crisis.",
        "10": "The approach is used to conduct a thorough investigation of<br>state-of-the-art classification models, and finds that in some -- but<br>not all -- cases, these models are capable of obtaining<br>accuracy very near optimal.",
        "11": "Recent progress in the development of modern computer vision techniques\u2014powered<br>by deep learning\u2014for medical applications, focusing on medical imaging, medical<br>video, and clinical deployment is surveyed.",
        "12": "SimpleTOD is a simple approach to task-oriented dialogue that uses<br>a single causal language model trained on all sub-tasks recast<br>as a single sequence prediction problem, which allows it to<br>fully leverage transfer learning from pre-trained, open domain, causal language<br>models such as GPT-2.",
        "13": "This work performs an extensive evaluation of skill discovery methods<br>on controlled environments and shows that EDL offers significant advantages,<br>such as overcoming the coverage problem, reducing the dependence of<br>learned skills on the initial state, and allowing the user<br>to define a prior over which behaviors should be learned.",
        "14": "Ambient light photovoltaic cells were developed to power autonomous Internet<br>of Things (IoT) devices, capable of machine learning, allowing the<br>on-device implementation of artificial intelligence.",
        "15": "PHOTON is presented, a robust, modular, cross-domain NLIDB that can<br>flag natural language input to which a SQL mapping cannot<br>be immediately determined and effectively improves the robustness of text-to-SQL<br>system against untranslatable user input.",
        "16": "",
        "17": "GeDi is proposed as an efficient method for using smaller<br>LMs as generative discriminators to guide generation from large LMs<br>to make them safer and more controllable, and is found<br>that GeDi gives stronger controllability than the state of the<br>art method while also achieving generation speeds more than 30<br>times faster.",
        "18": "This work addresses the challenging problem of training object detectors<br>with noisy annotations, where the noise contains a mixture of<br>label noise and bounding box noise, and proposes a two-step<br>noise correction method which achieves state-of-the-art performance.",
        "19": "Taylorized training can significantly close the performance gap between linearized<br>and full training and is a principled extension of linearized<br>training---a recently proposed theory for understanding the success of deep<br>learning.",
        "20": "Experimental results show that phone-based BPEs tend to yield more<br>accurate recognition systems than the character-based counterpart, and further improvement<br>can be obtained with a novel one-pass joint beam search<br>decoder, which efficiently combines phone- and character- based BPE systems.",
        "21": "A novel framework of Non-Autoregressive Dialog State Tracking (NADST) which<br>can factor in potential dependencies among domains and slots to<br>optimize the models towards better prediction of dialogue states as<br>a complete set rather than separate slots is proposed.",
        "22": "This work presents BRIDGE, a powerful sequential architecture for modeling<br>dependencies between natural language questions and relational databases in cross-DB<br>semantic parsing that effectively captures the desired cross-modal dependencies and<br>has the potential to generalize to more text-DB related tasks.",
        "23": "This work proposes a two-level deep reinforcement learning approach to<br>learn dynamic tax policies, based on economic simulations in which<br>both agents and a government learn and adapt, and shows<br>that AI-driven tax policies perform strongly in the face of<br>emergent tax-gaming strategies learned by AI agents.",
        "24": "CO-Search is presented, a retriever-ranker semantic search engine designed to<br>handle complex queries over the COVID-19 literature, potentially aiding overburdened<br>health workers in finding scientific answers during a time of<br>crisis.",
        "25": "The inner workings of the Transformer is analyzed and it<br>is shown that attention captures the folding structure of proteins,<br>connecting amino acids that are far apart in the underlying<br>sequence, but spatially close in the three-dimensional structure.",
        "26": "This work develops an inverse problem formulation to deconstruct the<br>products of combinatorial and compositional creativity into associative chains as<br>a form of post-hoc interpretation that matches the human creative<br>process.",
        "27": "Stochastic gradient descent is an implicit regularizer in SGD by<br>showing that explicitly penalizing the trace of the FIM can<br>significantly improve generalization, and it limits memorization by reducing the<br>learning speed of examples with noisy labels more than that<br>of the examples with clean labels.",
        "28": "P perturb the inflectional morphology of words to craft plausible<br>and semantically similar adversarial examples that expose biases in popular<br>NLP models, and show that adversarially fine-tuning them for a<br>single epoch significantly improves robustness without sacrificing performance on clean<br>data.",
        "29": "This work proposes WOAD, a weakly supervised framework that can<br>be trained using only video-class labels and obtains the state-of-the-art<br>results in the tasks of both online per-frame action recognition<br>and online detection of action start.",
        "30": "The results indicate the potential benefit of incorporating social capital<br>concepts in planning policies to control the spread of COVID-19,<br>and indicate a need for further research into this potentially<br>causal relationship, including examining interventions to increase social capital, community<br>health, and institutional health.",
        "31": "It is proved that model generalization ability is related to<br>the Hessian, the higher-order \u201csmoothness\u201d terms characterized by the Lipschitz<br>constant of the Hessians, and the scales of the parameters.",
        "32": "This paper attempts to bridge the gap with Hierarchical Accumulation<br>to encode parse tree structures into self-attention at constant time<br>complexity, and demonstrates that using hierarchical priors can compensate for<br>data shortage.",
        "33": "It is proved that the architectures with more skip connections<br>can converge faster than the other candidates, and thus are<br>selected by DARTS, and for the first time, theoretically and<br>explicitly reveals the impact of skip connections to fast network<br>optimization and its competitive advantage over other types of operations<br>in DARTS.",
        "34": "This work demonstrates that intermediate neural representations add more flexibility<br>to neural networks and can be advantageous over raw inputs,<br>and may provide a new perspective on why depth is<br>important in deep learning.",
        "35": "The experimental results show that the pre-trained task- oriented dialogue<br>BERT (ToD-BERT) surpasses BERT and other strong baselines in four<br>downstream task-oriented dialogue applications, including intention detection, dialogue state tracking,<br>dialogue act prediction, and response selection.",
        "36": "A new framework of conversational machine reading that comprises a<br>novel Explicit Memory Tracker (EMT) to track whether conditions listed<br>in the rule text have already been satisfied to make<br>a decision and is more interpretable by visualizing the entailment-oriented<br>reasoning process as the conversation flows.",
        "37": "This data indicates that TMA-based immunofluorescence profiling for biomarker discovery<br>is a promising method for personalized medicine, but its application<br>in clinical practice is still in its infancy.",
        "38": "This paper builds and evaluates translation models for seven target<br>languages from English, with several different copy mechanisms and an<br>XML-constrained beam search, and provides a detailed human analysis of<br>gaps between the model output and human translations for real-world<br>applications, including suitability for post-editing.",
        "39": "The dataset construction framework effectively merged heterogeneous sources from open<br>domain semantic parsing and spoken dialogue systems by utilizing techniques<br>including tree ontology annotation, question-answer pair to declarative sentence conversion,<br>and predicate unification, all with minimum post-editing.",
        "40": "It is shown that features obtained using self-supervised learning are<br>comparable to, or better than, supervised learning for domain generalization<br>in computer vision, and that multi-task learning of compatible pretext<br>tasks improvesdomain generalization performance as compared to training individual tasks<br>alone.",
        "41": "This work re-evaluate 14 automatic evaluation metrics in a comprehensive<br>and consistent fashion using neural summarization model outputs along with<br>expert and crowd-sourced human annotations and implements and shares a<br>toolkit that provides an extensible and unified API for evaluating<br>summarization models across a broad range of automatic metrics.",
        "42": "A parameterization method called Neural Bayes is introduced which allows<br>computing statistical quantities that are in general difficult to compute<br>and opens avenues for formulating new objectives for unsupervised representation<br>learning.",
        "43": "GraPPa is an effective pre-training approach for table semantic parsing<br>that learns a compositional inductive bias in the joint representations<br>of textual and tabular data and significantly outperforms RoBERTa-large as<br>the feature representation layers and establishes new state-of-the-art results on<br>all of them.",
        "44": "This paper introduces prototypes as latent variables to help find<br>the maximum-likelihood estimation of the network parameters in an Expectation-Maximization<br>framework and proposes ProtoNCE loss, a generalized version of the<br>InfoN CE loss for contrastive learning, which encourages representations to<br>be closer to their assigned prototypes.",
        "45": "This paper proposes to boost the discriminative ability by transferring<br>a natural language inference (NLI) model, and achieves more stable<br>and accurate in-domain and OOS detection accuracy than RoBERTa-based classifiers<br>and embedding-based nearest neighbor approaches.",
        "46": "An online structured meta-learning (OSML) framework Inspired by the knowledge<br>organization of human and hierarchical feature representation, OSML explicitly disentangles<br>the meta-learner as a meta-hierarchical graph with different knowledge blocks<br>that is able to quickly adapt to the new task.",
        "47": "This work proposes using k nearest neighbor (kNN) representations to<br>identify training examples responsible for a model's predictions and obtains<br>a corpus-level understanding of the model's behavior, and shows that<br>the kNN approach makes the finetuned model more robust to<br>adversarial inputs.",
        "48": "Data pre-processing makes the data clean so that the performance<br>of the classifier will be enhance, and result shows the<br>improve performance in sarcasm detection using the optimal feature sets.",
        "49": "This paper considers an intent as a combination of a<br>domain and an action, and proposes a composed variational natural<br>language generator (CLANG), a transformer-based conditional variational autoencoder that achieves<br>state-of-the-art performances on two real-world intent detection datasets.",
        "50": "This work poses protein engineering as an unsupervised sequence generation<br>problem in order to leverage the exponentially growing set of<br>proteins that lack costly, structural annotations and trains a 1.2B-parameter<br>language model, ProGen, on \u223c280M protein sequences conditioned on taxonomic<br>and keyword tags.",
        "51": "This work proposes DivideMix, a novel framework for learning with<br>noisy labels by leveraging semi-supervised learning techniques, which models the<br>per-sample loss distribution with a mixture model to dynamically divide<br>the training data into a labeled set with clean samples<br>and an unlabeled set with noisy samples.",
        "52": "ESRIT is a framework for commonsense reasoning about qualitative physics<br>in natural language that generates interpretable descriptions of physical events<br>using a data-to-text approach and learns to generate explanations of<br>how the physical simulation will causally evolve.",
        "53": "A deep learning model is presented that determines ERS from<br>H&E stained tissue, which could improve oncology decisions in under-resourced<br>settings and has the potential to augment clinicians\u2019 capabilities in<br>cancer prognosis and theragnosis by harnessing biological signals imperceptible to<br>the human eye.",
        "54": "This work demonstrates that this framework enables a pretrained entailment<br>model to work well on new entailment domains in a<br>few-shot setting, and shows its effectiveness as a unified solver<br>for several downstream NLP tasks such as question answering and<br>coreference resolution when the end-task annotations are limited.",
        "55": "It is found that using tokenized input increases the translation<br>accuracy compared to that of unparsed input, and although overall<br>Morfessor did best with a vocabulary size of 30k, the<br>first experiments show that BPE performed best withA reduced vocabulary<br>size.",
        "56": "MaskAugment, a controllable mechanism that augments text input by leveraging<br>the pre-trained Mask token from BERT model is proposed, and<br>an unsupervised teacher-student learning scheme is introduced to examine the<br>domain adaptation of DA taggers.",
        "57": "This work forms large-scale language model output detection as a<br>hypothesis testing problem to classify text as genuine or generated,<br>and shows that error exponents for particular language models are<br>bounded in terms of their perplexity, a standard measure of<br>language generation performance.",
        "58": "This work proposes the Evaluating Rationales And Simple English Reasoning<br>(ERASER) a benchmark to advance research on interpretable models in<br>NLP, and proposes several metrics that aim to capture how<br>well the rationales provided by models align with human rationales,<br>and also how faithful these rationales are.",
        "59": "A weakly-supervised, model-based approach for verifying factual consistency and identifying<br>conflicts between source documents and a generated summary substantially outperforms<br>previous models, including those trained with strong supervision using standard<br>datasets for natural language inference and fact checking.",
        "60": "This work shows that for a large class of networks<br>possessing a positive homogeneity property, similar bounds may be obtained<br>instead in terms of the norm of the product of<br>weights, which can be converted to generalization bounds for multi-class<br>classification that are comparable to, and in certain cases improve<br>upon, existing results in the literature.",
        "61": "A self-monitoring agent with two complementary components: (1) visual-textual co-grounding<br>module to locate the instruction completed in the past, the<br>instruction required for the next action, and the next moving<br>direction from surrounding images and (2) progress monitor to ensure<br>the grounded instruction correctly reflects the navigation progress.",
        "62": "An AI model was implemented to automate the analysis of<br>biomarkers by recognizing specific expression patterns of the markers of<br>interest in epithelial cells and normal stromal tissue to translate<br>the finding into predictions of recurrence and metastasis after radical<br>prostatectomy.",
        "63": "A unified, span-extraction approach leads to superior or comparable performance<br>in supplementary supervised pre-trained, low-data, and multi-task learning experiments on<br>several question answering, text classification, and regression benchmarks.",
        "64": "This paper explores knowledge distillation under the multi-task learning setting<br>and provides a general learning framework which is model agnostic<br>and can be easily applied on different future teacher model<br>architectures.",
        "65": "By separating the explicit neural structure learning and the parameter<br>estimation, the proposed method is capable of evolving neural structures<br>in an intuitively meaningful way, but also shows strong capabilities<br>of alleviating catastrophic forgetting in experiments.",
        "66": "It is discussed how pretrained models move through actor networks<br>as a kind of computationally immutable mobile, but that users<br>also act as agents of technological change by reinterpreting them<br>via fine-tuning and transfer and how this sociological understanding of<br>Pretrained models can inform AI governance frameworks for fairness, accountability,<br>and transparency.",
        "67": "A new graph-based recurrent retrieval approach that learns to retrieve<br>reasoning paths over the Wikipedia graph to answer multi-hop open-domain<br>questions and achieves significant improvement in HotpotQA, outperforming the previous<br>best model by more than 14 points.",
        "68": "CoSQL is presented, a corpus for building cross-domain, general-purpose database<br>(DB) querying dialogue systems that includes SQL-grounded dialogue state tracking,<br>response generation from query results, and user dialogue act prediction<br>and a set of strong baselines are evaluated.",
        "69": "A thorough ablation study is performed to evaluate the proposed<br>graph abstraction over the environment structure to accelerate the learning<br>of these tasks with significant advantages from the proposed framework<br>over baselines that lack world graph knowledge in terms of<br>performance and efficiency.",
        "70": "CTRL is released, a 1.63 billion-parameter conditional transformer language model,<br>trained to condition on control codes that govern style, content,<br>and task-specific behavior, providing more explicit control over text generation.",
        "71": "Sketch-Fill-A-R, a framework that uses a persona-memory to generate chit-chat<br>responses in three phases, outperforms a state-of-the-art baseline both quantitatively<br>and qualitatively on the Persona-Chat dataset.",
        "72": "This paper proposes a simple yet effective dual-strategy model for<br>DST, by adapting a single BERT-style reading comprehension model to<br>jointly handle both the categorical and non-categorical slots.",
        "73": "Based on the observation that adjacent natural language questions are<br>often linguistically dependent and their corresponding SQL queries tend to<br>overlap, the interaction history is utilized by editing the previous<br>predicted query to improve the generation quality.",
        "74": "This work collects human explanations for commonsense reasoning in the<br>form of natural language sequences and highlighted annotations in a<br>new dataset called Common Sense Explanations to train language models<br>to automatically generate explanations that can be used during training<br>and inference in a novel Commonsense Auto-Generated Explanation framework.",
        "75": "This paper proposes to mitigate noise incurred by imperfect label<br>assignment such that the contributions of anchors are dynamically determined<br>by a carefully constructed cleanliness score associated with each anchor,<br>and conducts extensive experiments on COCO.",
        "76": "This paper considers distribution shift as a shift in the<br>distribution of input features during test time that exhibit low<br>correlation with targets in the training set and evaluates existing<br>robust feature learning methods and regularization methods and compare them<br>against a baseline designed to specifically capture high correlation features<br>in training set.",
        "77": "The proposed global-to-local memory pointer networks can improve copy accuracy<br>and mitigate the common out-of-vocabulary problem, and is able to<br>improve over the previous state- of-the-art models in both simulated<br>bAbI Dialogue dataset and human-human Stanford Multi-domain Dialogue dataset on<br>automatic and human evaluation.",
        "78": "This work proposes a fully unsupervised model, Deleter, that is<br>able to discover an \"optimal deletion path\" for an arbitrary<br>sentence, where each intermediate sequence along the path is a<br>coherent subsequence of the previous one.",
        "79": "A unified, span-extraction approach leads to superior or comparable performance<br>in multi-task learning, low-data and supplementary supervised pretraining experiments on<br>several text classification and question answering benchmarks.",
        "80": "Cananical Correlation Analysis of the internal representations of a pre-<br>trained, multilingual BERT model reveals that the model partitions representations<br>for each language rather than using a common, shared, interlingual<br>space.",
        "81": "A novel deep learning based method is proposed to classify<br>cataract using fundus images by resorts to deep transfer learning<br>to reduce the number of parameters that need to be<br>trained.",
        "82": "Weakly supervised language localization networks (WSLLN) is proposed to detect<br>events in long, untrimmed videos given language queries to relieve<br>the annotation burden by training with only video-sentence pairs without<br>accessing to temporal locations of events.",
        "83": "This work critically evaluate key ingredients of the current research<br>setup: datasets, evaluation metrics, and models, and highlights three primary<br>shortcomings: automatically collected datasets leave the task underconstrained and may<br>contain noise detrimental to training and evaluation.",
        "84": "This paper distill the BERT model refined by multi-task learning<br>on seven datasets of the GLUE benchmark into a bidirectional<br>LSTM with attention mechanism, and provides a general learning framework.",
        "85": "The interaction history is utilized by editing the previous predicted<br>query to improve the generation quality of SQL queries and<br>the benefit of editing compared with the state-of-the-art baselines which<br>generate SQL from scratch is evaluated.",
        "86": "This work proposes a regularization approach based on IB, called<br>Entropy Penalty, that reduces the model's dependence on spurious features--<br>features corresponding to such spurious correlations, and shows that it<br>is able to generalize well on vanilla MNIST, MNIST-M and<br>SVHN datasets.",
        "87": "This work proposes a new method for teacher ensembles that<br>uses more informative network outputs under differential private stochastic gradient<br>descent and provide provable privacy guarantees and proposes a simple<br>weighted ensemble scheme that works more robustly across different teaching<br>settings.",
        "88": "",
        "89": "DIME is an information-theoretic DI for datasets, based on Fano\u2019s<br>inequality and a neural network estimation of the conditional entropy<br>of the sample-label distribution that is well-aligned with empirically observed<br>performance of state-of-the-art machine learning models.",
        "90": "An in-depth analysis of SParC is provided and it is<br>shown that it introduces new challenges compared to existing datasets<br>and requires generalization to unseen domains due to its cross-domain<br>nature and the unseen databases at test time.",
        "91": "The experimental results show that StartNet significantly outperforms the state-of-the-art<br>by 15%-30% p-mAP under the offset tolerance of 1-10 seconds<br>on THUMOS\u201914, and achieves comparable performance on ActivityNet with 10<br>times smaller time offset.",
        "92": "A surrogate objective function named, Taming MAML (TMAML), is proposed<br>that adds control variates into gradient estimation via automatic differentiation<br>and improves the quality of gradient estimation by reducing variance<br>without introducing bias.",
        "93": "The Coarse-grain Fine-grain Coattention Network (CFC), a new question answering<br>model that combines information from evidence across multiple documents that<br>obtains a new state-of-the-art result on the Qangaroo WikiHop multi-evidence<br>question answering task.",
        "94": "This work introduces a simple and effective model-free method to<br>learn from shaped distance-to-goal rewards on tasks where success depends<br>on reaching a goal state and introduces an auxiliary distance-based<br>reward based on pairs of rollouts to encourage diverse exploration.",
        "95": "This work proposes a novel method called competitive experience replay,<br>which efficiently supplements a sparse reward by placing learning in<br>the context of an exploration competition between a pair of<br>agents, creating a competitive game designed to drive exploration.",
        "96": "A novel voting mechanism is proposed, which is called an<br>Immutable Noisy ArgMax, that can bear very large random noising<br>from the teacher without affecting the useful information transferred to<br>the student.",
        "97": "A Transferable Dialogue State Generator (TRADE) that generates dialogue states<br>from utterances using copy mechanism, facilitating transfer when predicting (domain,<br>slot, value) triplets not encountered during training.",
        "98": "A methodology and the Genie toolkit that can handle new<br>compound commands with significantly less manual effort are presented and<br>design principles that make VAPL languages amenable to natural language<br>translation are proposed.",
        "99": "The bound suggests the generalization capability of reparameterizable RL is<br>related to multiple factors including \"smoothness\" of the environment transition,<br>reward and agent policy function class, and empirically verify the<br>relationship between thegeneralization gap and these factors through simulations.",
        "100": "This work proposes a model architecture and training strategy that<br>enables us to achieve state-of-the-art performance on the WikiText-103 data<br>set using a single GPU while being substantially faster than<br>an NVIDIA cuDNN LSTM-based model by utilizing the Quasi-Recurrent Neural<br>Network (QRNN), an adaptive softmax with weight tying, and longer<br>sequences within batches.",
        "101": "A simple sentence selector is proposed to select the minimal<br>set of sentences to feed into the QA model, and<br>the overall system achieves significant reductions in training and inference<br>times, with accuracy comparable to or better than the state-of-the-art<br>on SQuAD, NewsQA, TriviaQA and SQuad-Open.",
        "102": "It is qualitatively demonstrate learned frame usage can indicate the<br>difficulty of making classification decisions; easier samples need fewer frames<br>while harder ones require more, both at instance-level within the<br>same class and at class-level among different categories.",
        "103": "A neural network model with a novel intraattention that attends<br>over the input and continuously generated output separately, and a<br>new training method that combines standard supervised word prediction and<br>reinforcement learning (RL) that produces higher quality summaries.",
        "104": "It is found that while SGDR moves over barriers in<br>its trajectory, propositions claiming that it converges to and escapes<br>from multiple local minima are not substantiated by the empirical<br>results.",
        "105": "This work proposes an end-to-end transformer model, which employs a<br>self-attention mechanism, which enables the use of efficient non-recurrent structure<br>during encoding and leads to performance improvements.",
        "106": "A novel generative model based on cyclic-consistent generative adversarial network<br>(CycleGAN) for unsupervised non-parallel speech domain adaptation that employs multiple<br>independent discriminators on the power spectrogram, each in charge of<br>different frequency bands.",
        "107": "This paper proposes the Global-Locally Self-Attentive Dialogue State Tracker (GLAD),<br>which learns representations of the user utterance and previous system<br>actions with global-local modules and shows that this significantly improves<br>tracking of rare states.",
        "108": "It is proved that model generalization ability is related to<br>the Hessian, the higher-order \"smoothness\" terms characterized by the Lipschitz<br>constant of the Hessians, and the scales of the parameters.",
        "109": "This work proposes a mixed objective that combines cross entropy<br>loss with self-critical policy learning, and improves dynamic coattention networks<br>(DCN) with a deep residual coatt attention encoder that is<br>inspired by recent work in deep self-attention and residual networks.",
        "110": "This paper proposes an augmented cyclic adversarial learning model that<br>enforces the cycle-consistency constraint via an external task specific model,<br>which encourages the preservation of task-relevant content as opposed to<br>exact reconstruction.",
        "111": "This work takes existing state-of-the-art word level language models based<br>on LSTMs and QRNNs and extend them to both larger<br>vocabularies as well as character-level granularity, achieving state- of- the-art<br>results on character- level and word-level datasets.",
        "112": "This paper proposes an augmented cyclic adversarial learning model that<br>enforces the cycle-consistency constraint through an external task specific model,<br>which encourages the preservation of task-relevant content as opposed to<br>exact reconstruction.",
        "113": "This work reduces the impact of false negative supervision by<br>adopting a pretrained one-hop embedding model to estimate the reward<br>of unobserved facts and counter the sensitivity to spurious paths<br>of on-policy RL by forcing the agent to explore a<br>diverse set of paths using randomly generated edge masks.",
        "114": "This paper proposes an augmented cyclic adversarial learning model that<br>enforces the cycle-consistency constraint via an external task specific model,<br>which encourages the preservation of task-relevant content as opposed to<br>exact reconstruction.",
        "115": "Presented on August 28, 2018 at 12:15 p.m. in the<br>Pettit Microelectronics Research Center, Room 102 A/B.",
        "116": "Empirical analysis suggests that the reasons often quoted for the<br>success of cosine annealing are not evidenced in practice, and<br>that the effect of learning rate warmup is to prevent<br>the deeper layers from creating training instability.",
        "117": "This work decomposes the decoder into a contextual network that<br>retrieves relevant parts of the source document, and proposes a<br>pretrained language model that incorporates prior knowledge about language generation<br>to improve the level of abstraction of generated summaries.",
        "118": "This work proposes a domain-specific language (DSL) for use in<br>automated architecture search which can produce novel RNNs of arbitrary<br>depth and width and explores the novel architectures produced by<br>the RNN DSL for language modeling and machine translation domains.",
        "119": "To improve compositionality of multiple APIs, this work proposes SEQ2TT,<br>a Seq2Seq extension using a bottom-up encoding of grammar productions<br>for programs and a maxmargin loss, which obtains 84% accuracy<br>on trained programs and 67% on unseen combinations on the<br>ThingTalk dataset.",
        "120": "A neural network model with a novel intra-attention that attends<br>over the input and continuously generated output separately, and a<br>new training method that combines standard supervised word prediction and<br>reinforcement learning (RL) that produces higher quality summaries.",
        "121": "This work proposes a mixed objective that combines cross entropy<br>loss with self-critical policy learning, and improves dynamic coattention networks<br>(DCN) with a deep residual coatt attention encoder that is<br>inspired by recent work in deep self-attention and residual networks.",
        "122": "The model sequentially selects from detected objects and learns interactions<br>between objects that influence subsequent selections and outperforms the state<br>of the art architecture for VQA on multiple metrics that<br>evaluate counting.",
        "123": "A model is introduced that avoids this autoregressive property and<br>produces its outputs in parallel, allowing an order of magnitude<br>lower latency during inference, and achieves near-state-of-the-art performance on WMT<br>2016 English-Romanian.",
        "124": "Weighted Transformer is proposed, a Transformer with modified attention layers,<br>that not only outperforms the baseline network in BLEU score<br>but also converges 15-40% faster.",
        "125": "This work proposes a domain-specific language (DSL) for use in<br>automated architecture search which can produce novel RNNs of arbitrary<br>depth and width and explores the novel architectures produced by<br>the RNN DSL for language modeling and machine translation domains.",
        "126": "It is shown that joint training improves relative performance by<br>4% to 13% for the end-to-end model as compared to<br>the same model learned through maximum likelihood, and with policy<br>learning is able to directly optimize on the (otherwise non-differentiable)<br>performance metric.",
        "127": "This paper proposes the weight-dropped LSTM which uses DropConnect on<br>hidden-to-hidden weights as a form of recurrent regularization and introduces<br>NT-ASGD, a variant of the averaged stochastic gradient method, wherein<br>the averaging trigger is determined using a non-monotonic condition as<br>opposed to being tuned by the user.",
        "128": "Traditional regularization techniques are revisited, specifically L2 regularization on RNN<br>activations and slowness regularization over successive hidden states, to improve<br>the performance of RNNs on the task of language modeling.",
        "129": "SWATS is a hybrid strategy that begins training with an<br>adaptive method and switches to SGD when appropriate and is<br>capable of closing the generalization gap between SGD and Adam<br>on a majority of the tasks.",
        "130": "This work introduces a recursive neural network model, qanta, that<br>can reason over question text input by modeling textual compositionality<br>and applies it to a dataset of questions from a<br>trivia competition called quiz bowl.",
        "131": "Adding context vectors to a deep LSTM encoder from an<br>attentional sequence-to-sequence model trained for machine translation to contextualize word<br>vectors improves performance over using only unsupervised word and character<br>vectors on a wide variety of common NLP tasks.",
        "132": "This work proposes Seq2 SQL, a deep neural network for<br>translating natural language questions to corresponding SQL queries, and releases<br>WikiSQL, a dataset of 80654 hand-annotated examples of questions and<br>SQL queries distributed across 24241 tables fromWikipedia that is an<br>order of magnitude larger than comparable datasets.",
        "133": "This paper uses the encoder of an attentional sequence-to-sequence model<br>trained for machine translation to initialize models for other, different<br>language tasks, and shows that this transfer improves performance over<br>just using word vectors on a wide variety of common<br>NLP tasks.",
        "134": "The technology disclosed presents a novel spatial attention model that<br>uses current hidden state information of a decoder long short-term<br>memory (LSTM) to guide attention and to extract spatial image<br>features for use in image captioning.",
        "135": "Experiments on deep autoencoders, deep convolutional networks, and multilayer LSTMs<br>demonstrate better convergence and generalization compared to the original Hessian-free<br>approach and the Adam method.",
        "136": "This paper proposes a novel framework for efficient multi-task reinforcement<br>learning that trains agents to employ hierarchical policies that decide<br>when to use a previously learned policy and when to<br>learn a new skill.",
        "137": "Applying an AUC-based metric to the task of sentiment classification<br>finds significant efficiency gains with both a probability-threshold method for<br>reducing computational cost and one that uses a secondary decision<br>network.",
        "138": "The combination of data augmentation and dropout give a relative<br>performance improvement on both Wall Street Journal and LibriSpeech dataset<br>of over 20%, and the model performance is also competitive<br>with other end-to-end speech models on both datasets.",
        "139": "This work introduces a model for the task of machine<br>translation, pairing a recurrent neural network grammar encoder with a<br>novel attentional RNNG decoder and applying policy gradient reinforcement learning<br>to induce unsupervised tree structures on both the source and<br>target.",
        "140": "This work proposes and analyze a series of augmentations and<br>modifications to LSTM networks resulting in improved performance for text<br>classification datasets, and observes compounding improvements on traditional LSTMs using<br>Monte Carlo test-time model averaging, average pooling, and residual connections.",
        "141": "Quasi-recurrent neural networks (QRNNs), an approach to neural sequence modeling<br>that alternates convolutional layers, which apply in parallel across timesteps,<br>and a minimalist recurrent pooling function that applies inallel across<br>channels are introduced.",
        "142": "This work introduces a novel theoretical framework that facilitates better<br>learning in language modeling, and shows that this framework leads<br>to tying together the input embedding and the output projection<br>matrices, greatly reducing the number of trainable variables.",
        "143": "MetaMind\u2019s submissions to WMT \u201916 seek to push the state<br>of the art in one such task, English\u2192German newsdomain translation,<br>and integrate promising recent developments in NMT, including subword splitting<br>and back-translation for monolingual data augmentation.",
        "144": "MetaMind CEO and founder Richard Socher is interested in developing<br>new AI models that perform well across multiple different tasks<br>in natural language processing and computer vision.",
        "145": "This paper proposes a novel adaptive attention model with a<br>visual sentinel that sets the new state-of-the-art by a significant<br>margin on image captioning.",
        "146": "A joint many-task model together with a strategy for successively<br>growing its depth to solve increasingly complex tasks and uses<br>a simple regularization term to allow for optimizing all model<br>weights to improve one task\u2019s loss without exhibiting catastrophic interference<br>of the other tasks.",
        "147": "This work proposes and analyzes a series of architectural modifications<br>for LSTM networks resulting in improved performance for text classification<br>datasets and provides a simple, reliable, and high quality baseline<br>model.",
        "148": "This work introduces a recursive neural network model, qanta, that<br>can reason over question text input by modeling textual compositionality<br>and applies it to a dataset of questions from a<br>trivia competition called quiz bowl.",
        "149": "The Dynamic Coattention Network (DCN) for question answering first fuses<br>co-dependent representations of the question and the document in order<br>to focus on relevant parts of both, then a dynamic<br>pointing decoder iterates over potential answer spans to recover from<br>initial local maxima corresponding to incorrect answers.",
        "150": "The pointer sentinel-LSTM model achieves state of the art language<br>modeling performance on the Penn Treebank while using far fewer<br>parameters than a standard softmax LSTM and the freely available<br>WikiText corpus is introduced.",
        "151": "The new DMN+ model improves the state of the art<br>on both the Visual Question Answering dataset and the \\babi-10k<br>text question-answering dataset without supporting fact supervision.",
        "152": "This set of notes extends the discussion of word vectors<br>by seeing how they can be evaluated intrinsically and extrinsically<br>by discussing the example of word analogies as an intrinsic<br>evaluation technique and how it can be used to tune<br>word embedding techniques.",
        "153": "The Tree-LSTM is introduced, a generalization of LSTMs to tree-structured<br>network topologies that outperform all existing systems and strong LSTM<br>baselines on two tasks: predicting the semantic relatedness of two<br>sentences and sentiment classification.",
        "154": "The dynamic memory network (DMN), a neural network architecture which<br>processes input sequences and questions, forms episodic memories, and generates<br>relevant answers, is introduced.",
        "155": "This note introduces and discusses a new type of model<br>that is indeed a superset of the previously discussed Recurrent<br>Neural Network, and takes advantage of that recursive structure with<br>a model that respects it.",
        "156": "This work introduces a recursive neural network model, qanta, that<br>can reason over question text input by modeling textual compositionality<br>and applies it to a dataset of questions from a<br>trivia competition called quiz bowl.",
        "157": "The DT-RNN model, which uses dependency trees to embed sentences<br>into a vector space in order to retrieve images that<br>are described by those sentences, outperform other recursive and recurrent<br>neural networks, kernelized CCA and a bag-of-words baseline on the<br>tasks of finding an image that fits a sentence description<br>and vice versa.",
        "158": "This paper integrates peer and machine grading to preserve the<br>robustness of peer assessment and lower grading burden and provides<br>an example of how peer work and machine learning can<br>combine to improve the learning experience.",
        "159": "The RNN models of this thesis obtain state of the<br>art performance on paraphrase detection, sentiment analysis, relation classification, parsing,<br>image-sentence mapping and knowledge base completion, among other tasks.",
        "160": "A novel approach based on a hierarchical deep learning framework<br>which overcomes the aforementioned drawbacks is proposed and experimental results<br>on real world datasets show that the proposed framework outperforms<br>other state-of-the-art techniques.",
        "161": "This work introduces a recursive neural network model, qanta, that<br>can reason over question text input by modeling textual compositionality<br>and applies it to a dataset of questions from a<br>trivia competition called quiz bowl.",
        "162": "Global belief recursive neural networks (GB-RNNs) are introduced which are<br>based on the idea of extending purely feedforward neural networks<br>to include one feedbackward step during inference, which allows phrase<br>level predictions and representations to give feedback to words.",
        "163": "This SentimentTree visualization shows how word-level sentiments build up over<br>multi-word phrases to produce the overall sentiment associated with a<br>sentence and produces the current state-of-the-art accuracy on sentence-level sentiment<br>predictions.",
        "164": "A new global logbilinear regression model that combines the advantages<br>of the two major model families in the literature: global<br>matrix factorization and local context window methods and produces a<br>vector space with meaningful substructure.",
        "165": "A method to learn bilingual embeddings from a large unlabeled<br>corpus, while utilizing MT word alignments to constrain translational equivalence<br>is proposed, which significantly out-perform baselines in word semantic similarity.",
        "166": "An expressive neural tensor network suitable for reasoning over relationships<br>between two entities given a subset of the knowledge base<br>is introduced and performance can be improved when entities are<br>represented as an average of their constituting word vectors.",
        "167": "This paper combines recursive neural networks, where each morpheme is<br>a basic unit, with neural language models to consider contextual<br>information in learning morphologicallyaware word representations and proposes a novel<br>model capable of building representations for morphologically complex words from<br>their morphemes.",
        "168": "This project investigates three-class sentiment classification of Twitter data where<br>the labels are \u201cpositive\u2019, \u201cnegative\u201d, and \u201cneutral\u201c, and examines dataset<br>preprocessing specific to the natural language domain of tweets.",
        "169": "A Sentiment Treebank that includes fine grained sentiment labels for<br>215,154 phrases in the parse trees of 11,855 sentences and<br>presents new challenges for sentiment compositionality, and introduces the Recursive<br>Neural Tensor Network.",
        "170": "This work introduces a model that can recognize objects in<br>images even if no training data is available for the<br>object class, and uses novelty detection methods to differentiate unseen<br>classes from seen classes.",
        "171": "A neural tensor network (NTN) model is introduced which predicts<br>new relationship entries that can be added to the database<br>and can classify unseen relationships in WordNet with an accuracy<br>of 75.8%.",
        "172": "A Compositional Vector Grammar (CVG), which combines PCFGs with a<br>syntactically untied recursive neural network that learns syntactico-semantic, compositional vector<br>representations and improves performance on the types of ambiguities that<br>require semantic information such as PP attachments.",
        "173": "A framework for learning predictive structures from multiple tasks and<br>unlabeled data and a neural probabilistic language model for this<br>framework are presented.",
        "174": "The Stanford entries to the SANCL 2012 shared task on<br>parsing noncanonical language included a self-trained generative constituency parser, a<br>graph-based dependency parser, and a stacked dependency parser using the<br>output from the constituency parser as features while parsing.",
        "175": "A recursive neural network model that learns compositional vector representations<br>for phrases and sentences of arbitrary syntactic type and length<br>and can learn the meaning of operators in propositional logic<br>and natural language is introduced.",
        "176": "A new neural network architecture is presented which learns word<br>embeddings that better capture the semantics of words by incorporating<br>both local and global document context, and accounts for homonymy<br>and polysemy by learning multiple embedDings per word.",
        "177": "The principle goal of the tutorial is to make the<br>inner workings of these techniques transparent, intuitive and their results<br>interpretable, rather than black boxes labeled \"magic here\".",
        "178": "This work introduces a model based on a combination of<br>convolutional and recursive neural networks (CNN and RNN) for learning<br>features and classifying RGB-D images, which obtains state of the<br>art performance on a standardRGB-D object dataset while being more<br>accurate and faster during training and testing than comparable architectures<br>such as two-layer CNNs.",
        "179": "This paper considers applying different machine learning algorithms in the<br>realm of supervised learning and unsupervised learning in attempt to<br>predict the news stories that each user are most likely<br>to read from a set of all available stories, which<br>are much too large for the average users to parse<br>and find the most relevant ones.",
        "180": "A new nonparametric clustering model which combines the recently proposed<br>distance-dependent Chinese restaurant process (dd-CRP) and non-linear, spectral methods for<br>dimensionality reduction and improves the performance of the dd- CRP<br>in spectral space by incorporating the original similarity matrix in<br>its prior.",
        "181": "A max-margin structure prediction architecture based on recursive neural networks<br>that can successfully recover such structure both in complex scene<br>images as well as sentences is introduced.",
        "182": "This work introduces a method for paraphrase detection based on<br>recursive autoencoders (RAE) and unsupervised RAEs based on a novel<br>unfolding objective and learns feature vectors for phrases in syntactic<br>trees to measure word- and phrase-wise similarity between two sentences.",
        "183": "A novel machine learning framework based on recursive autoencoders for<br>sentence-level prediction of sentiment label distributions that outperform other state-of-the-art<br>approaches on commonly used datasets, without using any pre-defined sentiment<br>lexica or polarity shifting rules.",
        "184": "A semi-supervised model which segments and annotates images using very<br>few labeled images and a large unaligned text corpus to<br>relate image regions to text labels and outperforms the state-of-the-art<br>in annotation.",
        "185": "A recursive neural network architecture for jointly parsing natural language<br>and learning vector space representations for variable-sized inputs and captures<br>semantic information: For instance, the phrases \u201cdecline to comment\u201d and<br>\u201cwould not disclose the terms\u201d are close by in the<br>induced embedding space.",
        "186": "A probabilistic model of human memory performance in free recall<br>experiments is developed, conceptualizing memory retrieval as a dynamic latent<br>variable model and using Bayesian inference to represent uncertainty and<br>reason about the cognitive processes underlying memory.",
        "187": "A new database called \u201cImageNet\u201d is introduced, a large-scale ontology<br>of images built upon the backbone of the WordNet structure,<br>much larger in scale and diversity and much more accurate<br>than the current image datasets.",
        "188": "A fully automatic learning framework that is able to learn<br>robust scene models from noisy Web data such as images<br>and user tags from Flickr.com that significantly outperforms state-of-the-art algorithms.",
        "189": "This book investigates and extends a bootstrapping approach which permits<br>to extend high quality lexical resources with the help of<br>very large corpora.",
        "190": "This paper forms the segmentation task as a hierarchical learning<br>problem over 3 levels: border points, cross-segments and vessel pieces,<br>corresponding to the vessel's position, width and length, and forms<br>the marginal space learning paradigm.",
        "191": "",
        "192": "A method for the automatic construction of noun entries in<br>a semantic lexicon by modifying adjective, verb-deep-subject and verbdeep-object yields<br>very high precision for most semantic features, giving rise to<br>the fully automatic incorporation into the lexicon."
    },
    "venue": {
        "0": "npj Digital Medicine",
        "1": "Nature Biotechnology",
        "2": "Science Advances",
        "3": "arXiv.org",
        "4": "npj Digital Medicine",
        "5": "npj Digital Medicine",
        "6": "arXiv.org",
        "7": "",
        "8": "bioRxiv",
        "9": "npj Digital Medicine",
        "10": "Neural Information Processing Systems",
        "11": "npj Digital Medicine",
        "12": "Neural Information Processing Systems",
        "13": "International Conference on Machine Learning",
        "14": "Chemical Science",
        "15": "Annual Meeting of the Association for Computational Linguistics",
        "16": "",
        "17": "Conference on Empirical Methods in Natural Language Processing",
        "18": "arXiv.org",
        "19": "arXiv.org",
        "20": "Interspeech",
        "21": "International Conference on Learning Representations",
        "22": "Findings",
        "23": "arXiv.org",
        "24": "arXiv.org",
        "25": "bioRxiv",
        "26": "arXiv.org",
        "27": "International Conference on Machine Learning",
        "28": "Annual Meeting of the Association for Computational Linguistics",
        "29": "Computer Vision and Pattern Recognition",
        "30": "medRxiv",
        "31": "International Conference on Artificial Intelligence and Statistics",
        "32": "International Conference on Learning Representations",
        "33": "Neural Information Processing Systems",
        "34": "Neural Information Processing Systems",
        "35": "Conference on Empirical Methods in Natural Language Processing",
        "36": "Annual Meeting of the Association for Computational Linguistics",
        "37": "",
        "38": "Conference on Machine Translation",
        "39": "North American Chapter of the Association for Computational Linguistics",
        "40": "arXiv.org",
        "41": "Transactions of the Association for Computational Linguistics",
        "42": "arXiv.org",
        "43": "International Conference on Learning Representations",
        "44": "International Conference on Learning Representations",
        "45": "Conference on Empirical Methods in Natural Language Processing",
        "46": "Neural Information Processing Systems",
        "47": "arXiv.org",
        "48": "",
        "49": "Findings",
        "50": "bioRxiv",
        "51": "International Conference on Learning Representations",
        "52": "Annual Meeting of the Association for Computational Linguistics",
        "53": "Nature Communications",
        "54": "Conference on Empirical Methods in Natural Language Processing",
        "55": "arXiv.org",
        "56": "Conference on Empirical Methods in Natural Language Processing",
        "57": "Information Theory and Applications Workshop",
        "58": "Annual Meeting of the Association for Computational Linguistics",
        "59": "Conference on Empirical Methods in Natural Language Processing",
        "60": "arXiv.org",
        "61": "International Conference on Learning Representations",
        "62": "Journal of Urology",
        "63": "",
        "64": "",
        "65": "International Conference on Machine Learning",
        "66": "arXiv.org",
        "67": "International Conference on Learning Representations",
        "68": "Conference on Empirical Methods in Natural Language Processing",
        "69": "arXiv.org",
        "70": "arXiv.org",
        "71": "NLP4CONVAI",
        "72": "STARSEM",
        "73": "",
        "74": "Annual Meeting of the Association for Computational Linguistics",
        "75": "Computer Vision and Pattern Recognition",
        "76": "",
        "77": "International Conference on Learning Representations",
        "78": "arXiv.org",
        "79": "arXiv.org",
        "80": "Conference on Empirical Methods in Natural Language Processing",
        "81": "",
        "82": "Conference on Empirical Methods in Natural Language Processing",
        "83": "Conference on Empirical Methods in Natural Language Processing",
        "84": "arXiv.org",
        "85": "Conference on Empirical Methods in Natural Language Processing",
        "86": "arXiv.org",
        "87": "arXiv.org",
        "88": "arXiv.org",
        "89": "",
        "90": "Annual Meeting of the Association for Computational Linguistics",
        "91": "IEEE International Conference on Computer Vision",
        "92": "International Conference on Machine Learning",
        "93": "International Conference on Learning Representations",
        "94": "Neural Information Processing Systems",
        "95": "International Conference on Learning Representations",
        "96": "",
        "97": "Annual Meeting of the Association for Computational Linguistics",
        "98": "ACM-SIGPLAN Symposium on Programming Language Design and Implementation",
        "99": "International Conference on Machine Learning",
        "100": "",
        "101": "Annual Meeting of the Association for Computational Linguistics",
        "102": "Computer Vision and Pattern Recognition",
        "103": "",
        "104": "arXiv.org",
        "105": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
        "106": "Interspeech",
        "107": "Annual Meeting of the Association for Computational Linguistics",
        "108": "arXiv.org",
        "109": "",
        "110": "International Conference on Learning Representations",
        "111": "arXiv.org",
        "112": "arXiv.org",
        "113": "Conference on Empirical Methods in Natural Language Processing",
        "114": "",
        "115": "arXiv.org",
        "116": "International Conference on Learning Representations",
        "117": "Conference on Empirical Methods in Natural Language Processing",
        "118": "",
        "119": "",
        "120": "International Conference on Learning Representations",
        "121": "International Conference on Learning Representations",
        "122": "International Conference on Learning Representations",
        "123": "International Conference on Learning Representations",
        "124": "arXiv.org",
        "125": "International Conference on Learning Representations",
        "126": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
        "127": "International Conference on Learning Representations",
        "128": "arXiv.org",
        "129": "arXiv.org",
        "130": "",
        "131": "Neural Information Processing Systems",
        "132": "arXiv.org",
        "133": "NIPS 2017",
        "134": "",
        "135": "arXiv.org",
        "136": "International Conference on Learning Representations",
        "137": "Rep4NLP@ACL",
        "138": "arXiv.org",
        "139": "SPNLP@EMNLP",
        "140": "",
        "141": "International Conference on Learning Representations",
        "142": "International Conference on Learning Representations",
        "143": "Conference on Machine Translation",
        "144": "WASSA@NAACL-HLT",
        "145": "Computer Vision and Pattern Recognition",
        "146": "Conference on Empirical Methods in Natural Language Processing",
        "147": "arXiv.org",
        "148": "",
        "149": "International Conference on Learning Representations",
        "150": "International Conference on Learning Representations",
        "151": "International Conference on Machine Learning",
        "152": "",
        "153": "Annual Meeting of the Association for Computational Linguistics",
        "154": "International Conference on Machine Learning",
        "155": "",
        "156": "",
        "157": "Transactions of the Association for Computational Linguistics",
        "158": "ACM Conference on Learning @ Scale",
        "159": "",
        "160": "",
        "161": "Conference on Empirical Methods in Natural Language Processing",
        "162": "Neural Information Processing Systems",
        "163": "",
        "164": "Conference on Empirical Methods in Natural Language Processing",
        "165": "Conference on Empirical Methods in Natural Language Processing",
        "166": "Neural Information Processing Systems",
        "167": "Conference on Computational Natural Language Learning",
        "168": "",
        "169": "Conference on Empirical Methods in Natural Language Processing",
        "170": "Neural Information Processing Systems",
        "171": "International Conference on Learning Representations",
        "172": "Annual Meeting of the Association for Computational Linguistics",
        "173": "",
        "174": "",
        "175": "Conference on Empirical Methods in Natural Language Processing",
        "176": "Annual Meeting of the Association for Computational Linguistics",
        "177": "Annual Meeting of the Association for Computational Linguistics",
        "178": "Neural Information Processing Systems",
        "179": "",
        "180": "International Conference on Artificial Intelligence and Statistics",
        "181": "International Conference on Machine Learning",
        "182": "Neural Information Processing Systems",
        "183": "Conference on Empirical Methods in Natural Language Processing",
        "184": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
        "185": "",
        "186": "Neural Information Processing Systems",
        "187": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
        "188": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
        "189": "",
        "190": "IEEE International Symposium on Biomedical Imaging",
        "191": "",
        "192": "Nordic Conference of Computational Linguistics"
    }
}