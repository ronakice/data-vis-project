{
    "x": {
        "0": 4.505535125732422,
        "1": 2.61672306060791,
        "2": 2.7710254192352295,
        "3": 3.9825727939605713,
        "4": 2.929567575454712,
        "5": 2.6135852336883545,
        "6": 6.3521199226379395,
        "7": 6.273051738739014,
        "8": 4.133996963500977,
        "9": 2.7933621406555176,
        "10": 2.97023868560791,
        "11": 2.2184507846832275,
        "12": 2.2079007625579834,
        "13": 3.9303696155548096,
        "14": 4.558798313140869,
        "15": 5.744763374328613,
        "16": 5.704606533050537,
        "17": 2.8817522525787354,
        "18": 4.3605146408081055,
        "19": 5.199324131011963,
        "20": 5.6964430809021,
        "21": 3.578831672668457,
        "22": 4.799781799316406,
        "23": 6.278204441070557,
        "24": 3.906212568283081,
        "25": 1.6986790895462036,
        "26": 3.1348860263824463,
        "27": 3.1729540824890137,
        "28": 5.082170486450195,
        "29": 4.7491888999938965,
        "30": -0.384870320558548,
        "31": 6.0239691734313965,
        "32": 5.401763916015625,
        "33": 0.2756616771221161,
        "34": 5.421103000640869,
        "35": 5.279409408569336,
        "36": 4.9732513427734375,
        "37": 3.055915117263794,
        "38": 0.6381063461303711,
        "39": 6.687658309936523,
        "40": 6.122725486755371,
        "41": 1.5140544176101685,
        "42": 2.392252206802368,
        "43": 5.577489852905273,
        "44": 1.8075838088989258,
        "45": 0.07650408148765564,
        "46": 0.128468319773674,
        "47": 1.268821120262146,
        "48": 2.194945812225342,
        "49": 2.600041389465332,
        "50": 1.769400715827942,
        "51": 1.7782528400421143,
        "52": 3.5013620853424072,
        "53": 3.514174699783325,
        "54": 1.116525650024414
    },
    "y": {
        "0": -2.5223240852355957,
        "1": -4.081278324127197,
        "2": 0.8180580735206604,
        "3": -3.4760420322418213,
        "4": 0.4272916615009308,
        "5": -4.74221658706665,
        "6": -1.519171953201294,
        "7": -1.775303840637207,
        "8": -0.6725972294807434,
        "9": -4.378635883331299,
        "10": 0.5498461723327637,
        "11": -4.592014789581299,
        "12": 0.12285873293876648,
        "13": -1.530414342880249,
        "14": -1.6575123071670532,
        "15": -1.6995211839675903,
        "16": -1.8689130544662476,
        "17": -3.0411150455474854,
        "18": -2.9880874156951904,
        "19": -3.370617151260376,
        "20": -2.346367835998535,
        "21": -0.7467985153198242,
        "22": -2.9793481826782227,
        "23": -2.6456527709960938,
        "24": -2.774183750152588,
        "25": -3.6236610412597656,
        "26": -1.9259060621261597,
        "27": -1.9185724258422852,
        "28": -1.1646497249603271,
        "29": -3.034449815750122,
        "30": -2.3832955360412598,
        "31": -2.951035976409912,
        "32": -4.275801658630371,
        "33": -3.7642557621002197,
        "34": -0.03782538324594498,
        "35": -4.098338603973389,
        "36": 1.012874722480774,
        "37": -3.0463552474975586,
        "38": -2.8297386169433594,
        "39": -3.3366763591766357,
        "40": -2.471959114074707,
        "41": -3.579327344894409,
        "42": -0.3120425343513489,
        "43": -4.32941198348999,
        "44": -1.8053462505340576,
        "45": -1.0529366731643677,
        "46": -0.9990885257720947,
        "47": -2.063197374343872,
        "48": -2.9943370819091797,
        "49": -0.5432003736495972,
        "50": -1.8744803667068481,
        "51": -2.0058822631835938,
        "52": -0.15101487934589386,
        "53": -0.18766798079013824,
        "54": -2.364769697189331
    },
    "title": {
        "0": "Few-shot In-context Learning on Knowledge Base Question Answering",
        "1": "LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT",
        "2": "DreamEdit: Subject-driven Image Editing",
        "3": "Augmenting Black-box LLMs with Medical Textbooks for Clinical Question Answering",
        "4": "Subject-driven Text-to-Image Generation via Apprenticeship Learning",
        "5": "MARBLE: Music Audio Representation Benchmark for Universal Evaluation",
        "6": "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning",
        "7": "TheoremQA: A Theorem-driven Question Answering dataset",
        "8": "EDIS: Entity-Driven Image Search over Multimodal Web Content",
        "9": "MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response",
        "10": "MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing",
        "11": "MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training",
        "12": "Synthesizing Coherent Story with Auto-Regressive Latent Diffusion Models",
        "13": "MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text",
        "14": "DePlot: One-shot visual language reasoning by plot-to-table translation",
        "15": "Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks",
        "16": "Explanations from Large Language Models Make Small Reasoners Better",
        "17": "Controllable Dialogue Simulation with In-Context Learning",
        "18": "Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering",
        "19": "QA Is the New KR: Question-Answer Pairs as Knowledge Bases",
        "20": "Large Language Models are few(1)-shot Table Reasoners",
        "21": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
        "22": "HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data",
        "23": "Logical Natural Language Generation from Open-Domain Tables",
        "24": "Unsupervised Multi-hop Question Answering by Question Generation",
        "25": "Modeling Token-level Uncertainty to Learn Unknown Concepts in SLU via Calibrated Dirichlet Prior RNN",
        "26": "KGLM: Pretrained Knowledge-Grounded Language Model for Data-to-Text Generation",
        "27": "KGPT: Knowledge-Grounded Pre-Training for Data-to-Text Generation",
        "28": "Violin: A Large-Scale Dataset for Video-and-Language Inference",
        "29": "Open Question Answering over Tables and Text",
        "30": "Developments of NDE method of jacket welds for ITER In-Vessel coil joints",
        "31": "Logic2Text: High-Fidelity Natural Language Generation from Logical Forms",
        "32": "Generative Adversarial Zero-Shot Relational Learning for Knowledge Graphs",
        "33": "Mining Algorithm Roadmap in Scientific Publications",
        "34": "Meta Module Network for Compositional Visual Reasoning",
        "35": "Global Textual Relation Embedding for Relational Understanding",
        "36": "Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting",
        "37": "Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention",
        "38": "How Large a Vocabulary Does Text Classification Need? A Variational Approach to Vocabulary Selection",
        "39": "Towards Democratizing Data Science with Natural Language Interfaces",
        "40": "TabFact: A Large-scale Dataset for Table-based Fact Verification",
        "41": "Interpreting and Improving Deep Neural SLU Models via Vocabulary Importance",
        "42": "No Metrics Are Perfect: Adversarial Reward Learning for Visual Storytelling",
        "43": "Variational Knowledge Graph Reasoning",
        "44": "Approximate Distribution Matching for Sequence-to-Sequence Learning",
        "45": "A Variational Dirichlet Framework for Out-of-Distribution Detection",
        "46": "Enhancing the Robustness of Prior Network in Out-of-Distribution Detection",
        "47": "Triangular Architecture for Rare Language Translation",
        "48": "XL-NBT: A Cross-lingual Neural Belief Tracking Framework",
        "49": "Video Captioning via Hierarchical Reinforcement Learning",
        "50": "Neural Sequence Prediction by Coaching",
        "51": "Generative Bridging Network in Neural Sequence Prediction",
        "52": "A Semi-supervised Framework for Image Captioning",
        "53": "Bootstrap, Review, Decode: Using Out-of-Domain Textual Data to Improve Image Captioning",
        "54": "Guided Alignment Training for Topic-Aware Neural Machine Translation"
    },
    "year": {
        "0": 2023,
        "1": 2023,
        "2": 2023,
        "3": 2023,
        "4": 2023,
        "5": 2023,
        "6": 2023,
        "7": 2023,
        "8": 2023,
        "9": 2023,
        "10": 2023,
        "11": 2023,
        "12": 2022,
        "13": 2022,
        "14": 2022,
        "15": 2022,
        "16": 2022,
        "17": 2022,
        "18": 2022,
        "19": 2022,
        "20": 2022,
        "21": 2022,
        "22": 2020,
        "23": 2020,
        "24": 2020,
        "25": 2020,
        "26": 2020,
        "27": 2020,
        "28": 2020,
        "29": 2020,
        "30": 2020,
        "31": 2020,
        "32": 2020,
        "33": 2019,
        "34": 2019,
        "35": 2019,
        "36": 2019,
        "37": 2019,
        "38": 2019,
        "39": 2019,
        "40": 2019,
        "41": 2019,
        "42": 2018,
        "43": 2018,
        "44": 2018,
        "45": 2018,
        "46": 2018,
        "47": 2018,
        "48": 2018,
        "49": 2017,
        "50": 2017,
        "51": 2017,
        "52": 2016,
        "53": 2016,
        "54": 2016
    },
    "cluster": {
        "0": 1,
        "1": 4,
        "2": 0,
        "3": 1,
        "4": 0,
        "5": 4,
        "6": 2,
        "7": 2,
        "8": 1,
        "9": 4,
        "10": 0,
        "11": 4,
        "12": 0,
        "13": 1,
        "14": 1,
        "15": 2,
        "16": 2,
        "17": 4,
        "18": 1,
        "19": 1,
        "20": 2,
        "21": 0,
        "22": 1,
        "23": 2,
        "24": 1,
        "25": 4,
        "26": 4,
        "27": 4,
        "28": 2,
        "29": 1,
        "30": 3,
        "31": 2,
        "32": 2,
        "33": 4,
        "34": 0,
        "35": 2,
        "36": 4,
        "37": 2,
        "38": 3,
        "39": 2,
        "40": 2,
        "41": 4,
        "42": 0,
        "43": 2,
        "44": 4,
        "45": 3,
        "46": 3,
        "47": 4,
        "48": 4,
        "49": 0,
        "50": 4,
        "51": 4,
        "52": 0,
        "53": 0,
        "54": 4
    },
    "authors": {
        "0": "Tianle Li, Xueguang Ma, Alex Zhuang, Yu Gu, Yu Su, et al.",
        "1": "Le Zhuo, Ruibin Yuan, Jiahao Pan, Yi Ma, Li Yizhi, et al.",
        "2": "Tianle Li, Max Ku, Cong Wei, and Wenhu Chen",
        "3": "Yubo Wang, Xueguang Ma, and Wenhu Chen",
        "4": "Wenhu Chen, Hexiang Hu, Yandong Li, Nataniel Rui, Xuhui Jia, et al.",
        "5": "Ruibin Yuan, Yi Ma, Yizhi Li, Ge Zhang, Xingran Chen, et al.",
        "6": "Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, et al.",
        "7": "Wenhu Chen, Ming Yin, Max Ku, Yixin Wan, Xueguang Ma, et al.",
        "8": "Siqi Liu, Weixi Feng, Wenhu Chen, and W. Wang",
        "9": "Zihao Deng, Yi Ma, Yudong Liu, Rongchen Guo, Ge Zhang, et al.",
        "10": "Kai Zhang, Lingbo Mo, Wenhu Chen, Huan Sun, and Yu Su",
        "11": "Yizhi Li, Ruibin Yuan, Ge Zhang, Yi Ma, Xingran Chen, et al.",
        "12": "Xichen Pan, Pengda Qin, Yuhong Li, Hui Xue, and Wenhu Chen",
        "13": "Wenhu Chen, Hexiang Hu, Xi Chen, Pat Verga, and William W. Cohen",
        "14": "Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, et al.",
        "15": "Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen",
        "16": "SHIYANG LI, Jianshu Chen, Yelong Shen, Zhiyu Chen, Xinlu Zhang, et al.",
        "17": "Zekun Li, Wenhu Chen, SHIYANG LI, Hong Wang, Jingu Qian, et al.",
        "18": "Wenhu Chen, Pat Verga, Michiel de Jong, J. Wieting, and W. Cohen",
        "19": "Wenhu Chen, William W. Cohen, Michiel de Jong, Nitish Gupta, Alessandro Presta, et al.",
        "20": "Wenhu Chen",
        "21": "Wenhu Chen, Hexiang Hu, Chitwan Saharia, and William W. Cohen",
        "22": "Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang, et al.",
        "23": "Wenhu Chen, Jianshu Chen, Yunde Su, Zhiyu Chen, and William Yang Wang",
        "24": "Liangming Pan, Wenhu Chen, Wenhan Xiong, Min-Yen Kan, and William Yang Wang",
        "25": "Yilin Shen, Wenhu Chen, and Hongxia Jin",
        "26": "Wenhu Chen, Yu Su, Xifeng Yan, and W. Wang",
        "27": "Wenhu Chen, Yu Su, Xifeng Yan, and W. Wang",
        "28": "J. Liu, Wenhu Chen, Yu Cheng, Zhe Gan, Licheng Yu, et al.",
        "29": "Wenhu Chen, Ming-Wei Chang, Eva Schlinger, W. Wang, and William W. Cohen",
        "30": "Xiaochuan Liu, J. Qin, Chao Zhou, Wenhu Chen, Jianyang Tang, et al.",
        "31": "Zhiyu Chen, Wenhu Chen, Hanwen Zha, Xiyou Zhou, Yunkai Zhang, et al.",
        "32": "Pengda Qin, Xin Eric Wang, Wenhu Chen, Chunyun Zhang, Weiran Xu, et al.",
        "33": "Hanwen Zha, Wenhu Chen, Keqian Li, and Xifeng Yan",
        "34": "Wenhu Chen, Zhe Gan, Linjie Li, Yu Cheng, W. Wang, et al.",
        "35": "Zhiyu Chen, Hanwen Zha, Honglei Liu, Wenhu Chen, Xifeng Yan, et al.",
        "36": "SHIYANG LI, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, et al.",
        "37": "Wenhu Chen, Jianshu Chen, Pengda Qin, Xifeng Yan, and William Yang Wang",
        "38": "Wenhu Chen, Yu Su, Yilin Shen, Zhiyu Chen, Xifeng Yan, et al.",
        "39": "Xifeng Yan, W. Wang, Shengqi Yang, Fangqiu Han, Semih Yavuz, et al.",
        "40": "Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, et al.",
        "41": "Yilin Shen, Wenhu Chen, and Hongxia Jin",
        "42": "Xin Eric Wang, Wenhu Chen, Yuan-fang Wang, and William Yang Wang",
        "43": "Wenhu Chen, Wenhan Xiong, Xifeng Yan, and William Yang Wang",
        "44": "Wenhu Chen, Guanlin Li, Shujie Liu, Zhirui Zhang, Mu Li, et al.",
        "45": "Wenhu Chen, Yilin Shen, W. Wang, and Hongxia Jin",
        "46": "Wenhu Chen, Yilin Shen, Xin Eric Wang, and W. Wang",
        "47": "Shuo Ren, Wenhu Chen, Shujie Liu, Mu Li, M. Zhou, et al.",
        "48": "Wenhu Chen, Jianshu Chen, Yu Su, Xin Eric Wang, Dong Yu, et al.",
        "49": "Xin Eric Wang, Wenhu Chen, Jiawei Wu, Yuan-fang Wang, and William Yang Wang",
        "50": "Wenhu Chen, Guanlin Li, Shujie Liu, Zhirui Zhang, Mu Li, et al.",
        "51": "Wenhu Chen, Guanlin Li, Shuo Ren, Shujie Liu, Zhirui Zhang, et al.",
        "52": "Wenhu Chen, Aur\u00e9lien Lucchi, and Thomas Hofmann",
        "53": "Wenhu Chen, Aur\u00e9lien Lucchi, and Thomas Hofmann",
        "54": "Wenhu Chen, E. Matusov, Shahram Khadivi, and Jan-Thorsten Peter"
    },
    "first_author": {
        "0": false,
        "1": false,
        "2": false,
        "3": false,
        "4": true,
        "5": false,
        "6": false,
        "7": true,
        "8": false,
        "9": false,
        "10": false,
        "11": false,
        "12": false,
        "13": true,
        "14": false,
        "15": true,
        "16": false,
        "17": false,
        "18": true,
        "19": true,
        "20": true,
        "21": true,
        "22": true,
        "23": true,
        "24": false,
        "25": false,
        "26": true,
        "27": true,
        "28": false,
        "29": true,
        "30": false,
        "31": false,
        "32": false,
        "33": false,
        "34": true,
        "35": false,
        "36": false,
        "37": true,
        "38": true,
        "39": false,
        "40": true,
        "41": false,
        "42": false,
        "43": true,
        "44": true,
        "45": true,
        "46": true,
        "47": false,
        "48": true,
        "49": false,
        "50": true,
        "51": true,
        "52": true,
        "53": true,
        "54": true
    },
    "last_author": {
        "0": true,
        "1": false,
        "2": true,
        "3": true,
        "4": false,
        "5": false,
        "6": true,
        "7": false,
        "8": false,
        "9": false,
        "10": false,
        "11": false,
        "12": true,
        "13": false,
        "14": false,
        "15": false,
        "16": false,
        "17": false,
        "18": false,
        "19": false,
        "20": false,
        "21": false,
        "22": false,
        "23": false,
        "24": false,
        "25": false,
        "26": false,
        "27": false,
        "28": false,
        "29": false,
        "30": false,
        "31": false,
        "32": false,
        "33": false,
        "34": false,
        "35": false,
        "36": false,
        "37": false,
        "38": false,
        "39": false,
        "40": false,
        "41": false,
        "42": false,
        "43": false,
        "44": false,
        "45": false,
        "46": false,
        "47": false,
        "48": false,
        "49": false,
        "50": false,
        "51": false,
        "52": false,
        "53": false,
        "54": false
    },
    "middle_author": {
        "0": false,
        "1": true,
        "2": false,
        "3": false,
        "4": false,
        "5": true,
        "6": false,
        "7": false,
        "8": true,
        "9": true,
        "10": true,
        "11": true,
        "12": false,
        "13": false,
        "14": true,
        "15": false,
        "16": true,
        "17": true,
        "18": false,
        "19": false,
        "20": false,
        "21": false,
        "22": false,
        "23": false,
        "24": true,
        "25": true,
        "26": false,
        "27": false,
        "28": true,
        "29": false,
        "30": true,
        "31": true,
        "32": true,
        "33": true,
        "34": false,
        "35": true,
        "36": true,
        "37": false,
        "38": false,
        "39": true,
        "40": false,
        "41": true,
        "42": true,
        "43": false,
        "44": false,
        "45": false,
        "46": false,
        "47": true,
        "48": false,
        "49": true,
        "50": false,
        "51": false,
        "52": false,
        "53": false,
        "54": false
    },
    "author_of_interest": {
        "0": "Wenhu Chen",
        "1": "Wenhu Chen",
        "2": "Wenhu Chen",
        "3": "Wenhu Chen",
        "4": "Wenhu Chen",
        "5": "Wenhu Chen",
        "6": "Wenhu Chen",
        "7": "Wenhu Chen",
        "8": "Wenhu Chen",
        "9": "Wenhu Chen",
        "10": "Wenhu Chen",
        "11": "Wenhu Chen",
        "12": "Wenhu Chen",
        "13": "Wenhu Chen",
        "14": "Wenhu Chen",
        "15": "Wenhu Chen",
        "16": "Wenhu Chen",
        "17": "Wenhu Chen",
        "18": "Wenhu Chen",
        "19": "Wenhu Chen",
        "20": "Wenhu Chen",
        "21": "Wenhu Chen",
        "22": "Wenhu Chen",
        "23": "Wenhu Chen",
        "24": "Wenhu Chen",
        "25": "Wenhu Chen",
        "26": "Wenhu Chen",
        "27": "Wenhu Chen",
        "28": "Wenhu Chen",
        "29": "Wenhu Chen",
        "30": "Wenhu Chen",
        "31": "Wenhu Chen",
        "32": "Wenhu Chen",
        "33": "Wenhu Chen",
        "34": "Wenhu Chen",
        "35": "Wenhu Chen",
        "36": "Wenhu Chen",
        "37": "Wenhu Chen",
        "38": "Wenhu Chen",
        "39": "Wenhu Chen",
        "40": "Wenhu Chen",
        "41": "Wenhu Chen",
        "42": "Wenhu Chen",
        "43": "Wenhu Chen",
        "44": "Wenhu Chen",
        "45": "Wenhu Chen",
        "46": "Wenhu Chen",
        "47": "Wenhu Chen",
        "48": "Wenhu Chen",
        "49": "Wenhu Chen",
        "50": "Wenhu Chen",
        "51": "Wenhu Chen",
        "52": "Wenhu Chen",
        "53": "Wenhu Chen",
        "54": "Wenhu Chen"
    },
    "reference_count": {
        "0": 59,
        "1": 48,
        "2": 41,
        "3": 39,
        "4": 44,
        "5": 57,
        "6": 77,
        "7": 57,
        "8": 39,
        "9": 25,
        "10": 44,
        "11": 59,
        "12": 46,
        "13": 43,
        "14": 50,
        "15": 40,
        "16": 54,
        "17": 57,
        "18": 49,
        "19": 55,
        "20": 48,
        "21": 52,
        "22": 28,
        "23": 48,
        "24": 48,
        "25": 40,
        "26": 55,
        "27": 56,
        "28": 78,
        "29": 47,
        "30": 12,
        "31": 53,
        "32": 31,
        "33": 43,
        "34": 52,
        "35": 34,
        "36": 42,
        "37": 38,
        "38": 40,
        "39": 109,
        "40": 49,
        "41": 22,
        "42": 43,
        "43": 25,
        "44": 39,
        "45": 40,
        "46": 40,
        "47": 26,
        "48": 30,
        "49": 50,
        "50": 28,
        "51": 33,
        "52": 38,
        "53": 40,
        "54": 24
    },
    "citation_count": {
        "0": 8,
        "1": 1,
        "2": 4,
        "3": 1,
        "4": 23,
        "5": 2,
        "6": 7,
        "7": 13,
        "8": 0,
        "9": 0,
        "10": 7,
        "11": 9,
        "12": 14,
        "13": 19,
        "14": 12,
        "15": 150,
        "16": 41,
        "17": 10,
        "18": 20,
        "19": 3,
        "20": 28,
        "21": 50,
        "22": 168,
        "23": 110,
        "24": 41,
        "25": 5,
        "26": 0,
        "27": 100,
        "28": 50,
        "29": 108,
        "30": 0,
        "31": 50,
        "32": 52,
        "33": 15,
        "34": 46,
        "35": 4,
        "36": 761,
        "37": 106,
        "38": 25,
        "39": 0,
        "40": 250,
        "41": 2,
        "42": 131,
        "43": 105,
        "44": 0,
        "45": 16,
        "46": 9,
        "47": 32,
        "48": 31,
        "49": 199,
        "50": 2,
        "51": 10,
        "52": 13,
        "53": 9,
        "54": 101
    },
    "tldr": {
        "0": "This work proposes KB-BINDER, which for the first time enables<br>few-shot in- context learning over KBQA tasks and can achieve<br>a strong performance with only a few in-context demonstrations.",
        "1": "",
        "2": "This work proposes two novel subject-driven sub-tasks, i.e., Subject Replacement<br>and Subject Addition, and devise an innovative method DreamEditor to<br>resolve these tasks by performing iterative generation, which enables a<br>smooth adaptation to the customized subject.",
        "3": "Despite being 100 times smaller, it is found that medical<br>textbooks as the retrieval corpus serves as a more valuable<br>external knowledge source than Wikipedia in the medical domain.",
        "4": "Human evaluation shows that SuTI significantly outperforms existing models like<br>InstructPix2Pix, Textual Inversion, Imagic, Prompt2Prompt, Re-Imagen and DreamBooth, especially on<br>the subject and text alignment aspects.",
        "5": "The Music Audio Representation Benchmark for universaL Evaluation, termed MARBLE,<br>aims to provide a benchmark for various Music Information Retrieval<br>(MIR) tasks by defining a comprehensive taxonomy with four hierarchy<br>levels, including acoustic, performance, score, and high-level description.",
        "6": "The MAmmoTH series substantially outperform existing open-source models on nine<br>mathematical reasoning datasets across all scales with an average accuracy<br>gain between 16% and 32%, and underscores the importance of<br>diverse problem coverage and the use of hybrid rationales in<br>developing superior math generalist models.",
        "7": "This paper introduces TheoremQA, the first theorem-driven question-answering dataset designed<br>to evaluate AI models' capabilities to apply theorems to solve<br>challenging science problems and finds that GPT-4's capabilities to solve<br>these problems are unparalleled, achieving an accuracy of 51% with<br>Program-of-Thoughts Prompting.",
        "8": "The experimental results show that EDIS challenges state-of-the-art methods with<br>dense entities and a large-scale candidate set, and the ablation<br>study proves that fusing textual features with visual features is<br>critical in improving retrieval results.",
        "9": "MusiLingo employs a single projection layer to align music representations<br>from the pre-trained frozen music audio model MERT with the<br>frozen LLaMA language model, bridging the gap between music audio<br>and textual contexts.",
        "10": "This work introduces MagicBrush, the first large-scale, manually annotated dataset<br>for instruction-guided real image editing that covers diverse scenarios: single-turn,<br>multi- turn, mask-provided, and mask-free editing, and fine-tune InstructPix2Pix on<br>it and shows that the new model can produce much<br>better images according to human evaluation.",
        "11": "An acoustic Music undERstanding model with large-scale self-supervised Training (MERT),<br>which incorporates teacher models to provide pseudo labels in the<br>masked language modelling (MLM) style acoustic pre-training, which outperforms conventional<br>speech and audio approaches in terms of performance.",
        "12": "This work proposes AR-LDM, a latent diffusion model auto-regressively conditioned<br>on history captions and generated images that achieves SoTA FID<br>scores on PororoSV, FlintstonesV, and the newly introduced challenging dataset<br>VIST containing natural images.",
        "13": "The first Multimodal Retrieval-Augmented Transformer (MuRAG) is proposed, which accesses<br>an external non-parametric multimodal memory to augment language generation and<br>achieves state-of-the-art accuracy.",
        "14": "DePlot+LLM with just one-shot prompting achieves a 24.0% improvement over<br>finetuned SOTA on human-written queries from the task of chart<br>QA, and can be used off-the-shelf together with LLMs in<br>a plug-and-play fashion.",
        "15": "Under both few-shot and zero-shot settings, PoT can show an<br>average performance gain over CoT by around 12\\% across all<br>the evaluated datasets, and by combining PoT with self-consistency decoding,<br>can achieve SoTA performance on all math problem datasets and<br>near-SoTAperformance on financial datasets.",
        "16": "This paper considers the problem of leveraging the explanations generated<br>by LLM to improve the training of small reasoners, which<br>are more favorable in real-production deployment due to their low<br>cost.",
        "17": "Experimental results on the MultiWOZ dataset demonstrate that training a<br>model on the simulated dialogues leads to even better performance<br>than using the same amount of human-generated dialogues under the<br>challenging low-resource settings, with as few as 85 dialogues as<br>a seed.",
        "18": "A new QA system that augments a text-to-text model with<br>a large memory of question-answer pairs, and a new pre-training<br>task for the latent step of question retrieval, which substantially<br>simplifies training and greatly improves performance on smaller QA benchmarks.",
        "19": "It is argued that the proposed type of KB has<br>many of the key advantages of a traditional symbolic KB:<br>in particular, it consists of small modular components, which can<br>be combined compositionally to answer complex queries, including relational queries<br>and queries involving ``multi-hop'' inferences.",
        "20": "This paper evaluated LLMs on popular table QA and fact<br>verification datasets like WikiTableQuestion, FetaQA, TabFact, and FEVEROUS and found<br>that LLMs are competent at complex reasoning over table structures,<br>though these models are not pre-trained on any table corpus.",
        "21": "The Retrieval-Augmented Text-to-Image Generator (Re-Imagen), a generative model that uses<br>retrieved information to produce high-fidelity and faithful images, even for<br>rare or unseen entities, is presented.",
        "22": "HybridQA is presented, a new large-scale question-answering dataset that requires<br>reasoning on heterogeneous information and can serve as a challenging<br>benchmark to study question answering withheterogeneous information.",
        "23": "A new NLG task where a model is tasked with<br>generating natural language statements that can be logically entailed by<br>the facts in an open-domain semi-structured table is suggested, and<br>new automatic metrics to evaluate the fidelity of generation models<br>w.r.t. logical inference are proposed.",
        "24": "This work proposes MQA-QG, an unsupervised framework that can generate<br>human-like multi-hop training data from both homogeneous and heterogeneous data<br>sources and shows that pretraining the QA system with the<br>generated data would greatly reduce the demand for human-annotated training<br>data.",
        "25": "A Dirichlet Prior RNN is designed to model high-order uncertainty<br>by degenerating as softmax layer for RNN model training to<br>enhance the uncertainty modeling robustness and a novel multi-task training<br>to calibrate theDirichlet concentration parameters is proposed.",
        "26": "A knowledge-grounded pre-training (KGPT), which consists of a general knowledge-<br>grounded generation model to generate knowledge-enriched text and a pretraining<br>paradigm on a massive knowledgegrounded text corpus crawled from the<br>web to address data-to-text generation issues.",
        "27": "A knowledge-grounded pre-training (KGPT) is proposed, which consists of two<br>parts, 1) a general knowledge-Grounded generation model to generate knowledge-enriched<br>text and 2) a pre- training paradigm on a massive<br>knowledge- grounded text corpus crawled from the web.",
        "28": "A new large-scale dataset, named Violin (VIdeO-and-Language INference), is introduced<br>for this task, which consists of 95,322 video-hypothesis pairs from<br>15,887 video clips, spanning over 582 hours of video.",
        "29": "This work considers for the first time open QA over<br>both tabular and textual data and presents a new large-scale<br>dataset Open Table-and-Text Question Answering (OTT-QA) to evaluate performance on<br>this task.",
        "30": "",
        "31": "This work forms high-fidelity NLG as generation from logical forms<br>in order to obtain controllable and faithful generations, and presents<br>a new large-scale dataset, Logic2Text, with 10,753 descriptions involving common<br>logic types paired with the underlying logical forms.",
        "32": "A novel formulation of zero-shot learning is considered, which is<br>model-agnostic that could be potentially applied to any version of<br>KG embeddings, and consistently yields performance improvements on NELL and<br>Wiki dataset.",
        "33": "This work defines a new problem called mining algorithm roadmap<br>in scientific publications, and proposes a new weakly supervised method<br>to build the roadmap, and presents a proposed algorithm that<br>shows its superiority over the baseline methods on the proposed<br>task.",
        "34": "This work proposes Meta Module Network (MMN), a more powerful<br>NMN architecture centered on a novel meta module, which can<br>take in function recipes and morph into diverse instance modules<br>dynamically, inheriting the strong explainability and compositionality of NMN.",
        "35": "This work investigates how to learn a general-purpose embedding of<br>textual relations, defined as the shortest dependency path between entities,<br>and creates the largest distant supervision dataset by linking the<br>entire English ClueWeb09 corpus to Freebase.",
        "36": "First, convolutional self-attention is proposed by producing queries and keys<br>with causal convolution so that local context can be better<br>incorporated into attention mechanism, and LogSparse Transformer is proposed, improving<br>forecasting accuracy for time series with fine granularity and strong<br>long-term dependencies under constrained memory budget.",
        "37": "A multi-layer hierarchical graph is exploited to build a hierarchical<br>disentangled self-attention network, where each act is represented as a<br>root-to-leaf route on the graph, and combinatorially many dialog act<br>semantics can be modeled to control the neural response generation.",
        "38": "A more sophisticated variational vocabulary dropout (VVD) based on variational<br>dropout to perform vocabulary selection, which can intelligently select the<br>subset of the vocabulary to achieve the required performance.",
        "39": "Towards Democratizing Data Science with Natural Language Interfaces: Towards Democratizing<br>data science with natural language Interfaces.",
        "40": "A large-scale dataset with 16k Wikipedia tables as the evidence<br>for 118k human-annotated natural language statements, which are labeled as<br>either ENTAILED or REFUTED is constructed and two different models<br>are designed: Table-BERT and Latent Program Algorithm (LPA).",
        "41": "This paper studies the vocabulary importance using a novel Embedding<br>Sparse Structure Learning (SparseEmb) approach, and utilizes SparseEmb to sanitize<br>the training data based on the selected useless words as<br>well as the model re-validation during training.",
        "42": "Though automatic evaluation indicates slight performance boost over state-of-the-art (SOTA)<br>methods in cloning expert behaviors, human evaluation shows that this<br>approach achieves significant improvement in generating more human-like stories than<br>SOTA systems.",
        "43": "This paper tackles a practical query answering task involving predicting<br>the relation of a given entity pair and frames this<br>prediction problem as an inference problem in a probabilistic graphical<br>model and aims at resolving it from a variational inference<br>perspective.",
        "44": "This algorithm can alleviate the data sparsity issues in sequence<br>learning by locally augmenting more unseen data pairs and increasing<br>the model's robustness, and the superiority of the proposed algorithm<br>over the other competing algorithms is demonstrated.",
        "45": "This paper designs a higher-order uncertainty metric for deep neural<br>networks and investigates its effectiveness under the out-of-distribution detection task<br>proposed by Hendricks 2016baseline, and proposes an auxiliary objective function<br>to discriminate against synthesized adversarial examples to further increase the<br>robustness of the proposed uncertainty measure.",
        "46": "A perturbed prior network architecture is proposed, which can efficiently<br>separate model- level uncertainty from data-level uncertainty via prior entropy<br>viaPrior entropy, and a concentration perturbation algorithm, which adaptively adds<br>noise to concentration parameters so that the in- and out-of-distribution<br>images are better separable.",
        "47": "Empirical results demonstrate that the proposed novel triangular training architecture<br>(TA-NMT) significantly improves the translation quality of rare languages on<br>MultiUN and IWSLT2012 datasets, and achieves even better performance combining<br>back-translation methods.",
        "48": "A cross-lingual state tracking framework is built that assumes that<br>there exists a source language with dialog belief tracking annotations<br>while the target languages have no annotated dialog data of<br>any form, and discusses two types of common parallel resources:<br>bilingual corpus and bilingual dictionary.",
        "49": "A novel hierarchical reinforcement learning framework for video captioning, where<br>a high-level Manager module learns to design sub-goals and a<br>low-level Worker module recognizes the primitive actions to fulfill the<br>sub-goal.",
        "50": "This paper introduces a hybrid-coach framework to combine these two<br>existing algorithms so that the supervision from MLE can stabilize<br>RL training while RL can incorporate task-level loss into MLE<br>training.",
        "51": "A novel generative bridging network (GBN) is proposed to train<br>sequence prediction models, which contains a generator and a bridge,<br>and three independent GBNs are proposed, namely uniform GBN, language-model<br>GBN and coaching GBN.",
        "52": "The main benefit of this architecture is that it synthesizes<br>meaningful thought vectors that capture salient image properties and then<br>applies a soft attentive decoder to decode the thought vectors<br>and generate image captions.",
        "53": "A novel way of using out-of-domain textual data to enhance<br>the performance of existing image captioning systems is proposed and<br>the bootstrap learning method can largely improve performance and help<br>the model to generate more accurate and diverse captions.",
        "54": "This paper shows that the novel guided alignment training approach<br>improves translation quality on real-life e-commerce texts consisting of product<br>titles and descriptions, overcoming the problems posed by many unknown<br>words and a large type/token ratio."
    },
    "venue": {
        "0": "Annual Meeting of the Association for Computational Linguistics",
        "1": "arXiv.org",
        "2": "arXiv.org",
        "3": "arXiv.org",
        "4": "arXiv.org",
        "5": "arXiv.org",
        "6": "arXiv.org",
        "7": "arXiv.org",
        "8": "arXiv.org",
        "9": "arXiv.org",
        "10": "arXiv.org",
        "11": "arXiv.org",
        "12": "arXiv.org",
        "13": "Conference on Empirical Methods in Natural Language Processing",
        "14": "Annual Meeting of the Association for Computational Linguistics",
        "15": "arXiv.org",
        "16": "arXiv.org",
        "17": "Conference on Empirical Methods in Natural Language Processing",
        "18": "Conference of the European Chapter of the Association for Computational Linguistics",
        "19": "AAAI Conference on Artificial Intelligence",
        "20": "Findings",
        "21": "International Conference on Learning Representations",
        "22": "Findings",
        "23": "Annual Meeting of the Association for Computational Linguistics",
        "24": "North American Chapter of the Association for Computational Linguistics",
        "25": "arXiv.org",
        "26": "Conference on Empirical Methods in Natural Language Processing",
        "27": "Conference on Empirical Methods in Natural Language Processing",
        "28": "Computer Vision and Pattern Recognition",
        "29": "International Conference on Learning Representations",
        "30": "Journal of Physics: Conference Series",
        "31": "Findings",
        "32": "AAAI Conference on Artificial Intelligence",
        "33": "Knowledge Discovery and Data Mining",
        "34": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
        "35": "Annual Meeting of the Association for Computational Linguistics",
        "36": "Neural Information Processing Systems",
        "37": "Annual Meeting of the Association for Computational Linguistics",
        "38": "North American Chapter of the Association for Computational Linguistics",
        "39": "",
        "40": "International Conference on Learning Representations",
        "41": "Interspeech",
        "42": "Annual Meeting of the Association for Computational Linguistics",
        "43": "North American Chapter of the Association for Computational Linguistics",
        "44": "arXiv.org",
        "45": "",
        "46": "arXiv.org",
        "47": "Annual Meeting of the Association for Computational Linguistics",
        "48": "Conference on Empirical Methods in Natural Language Processing",
        "49": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
        "50": "arXiv.org",
        "51": "",
        "52": "",
        "53": "arXiv.org",
        "54": "Conference of the Association for Machine Translation in the Americas"
    }
}